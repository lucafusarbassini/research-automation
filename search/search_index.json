{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ricet","text":"<p>Automate scientific research using Claude Code with multi-agent orchestration, overnight autonomous execution, and comprehensive tooling.</p> <p>Created by Luca Fusar Bassini.</p> <p>ricet is a CLI tool and framework that manages the full lifecycle of scientific research projects. It pairs Claude Code with a structured agent system, persistent knowledge, reproducibility enforcement, and a complete paper pipeline -- so you can focus on the science while automation handles the scaffolding.</p>"},{"location":"#why-ricet","title":"Why ricet?","text":"<p>Running a research project involves dozens of repetitive tasks: environment setup, literature searches, experiment tracking, figure generation, paper writing, and more. ricet provides a single <code>ricet</code> command that orchestrates all of these through specialized AI agents operating inside a safe, containerized environment.</p> Problem Solution Ad-hoc experiment tracking Reproducibility engine with run logs, artifact registry, and dataset hashing Scattered knowledge Persistent encyclopedia that grows automatically with every task Tedious boilerplate Project templates with agents, hooks, LaTeX, and CI/CD out of the box Unsafe autonomous runs Docker isolation with four-tier permission model Manual paper formatting Integrated LaTeX pipeline with colorblind-safe figures and citation management"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Install Claude Code (requires Node.js 20+)\nnpm install -g @anthropic-ai/claude-code\n\n# Clone the repository\ngit clone https://github.com/lucafusarbassini/research-automation\ncd research-automation\n\n# Install the CLI\npip install -e .\n\n# Create your first project\nricet init my-project\n\n# Start an interactive session\ncd my-project\nricet start\n\n# Or run overnight\nricet overnight --iterations 20\n</code></pre> <p>See the full Quickstart Tutorial for a step-by-step walkthrough.</p>"},{"location":"#feature-highlights","title":"Feature Highlights","text":"<ul> <li>Multi-Agent Orchestration -- Master agent routes tasks to Researcher, Coder, Reviewer, Falsifier, Writer, and Cleaner sub-agents, each with dedicated budgets and system prompts.</li> <li>70+ MCP Integrations -- Automatically discovered and loaded based on task type, organized in eight tiers from essential tools to cloud infrastructure.</li> <li>Overnight Mode -- Autonomous execution loop with auto-debug, resource monitoring, and recovery. Run <code>ricet overnight</code> and check results in the morning.</li> <li>Knowledge Accumulation -- A project encyclopedia that records learnings, decisions, successful approaches, and failed attempts. Supports HNSW vector search when claude-flow is available.</li> <li>Paper Pipeline -- LaTeX template, publication-quality figure generation with matplotlib rcParams, BibTeX citation management, and one-command compilation.</li> <li>Reproducibility -- Every experiment run is logged with parameters, metrics, git hash, and SHA-256 artifact checksums.</li> <li>Docker Isolation -- Safe containerized execution with four permission levels (Safe, Moderate, Elevated, Dangerous).</li> <li>3-Tier Model Routing -- Automatic model selection (Haiku/Sonnet/Opus) based on task complexity, with budget-aware fallback.</li> <li>Progressive Instructions -- Five-phase protocol: Orient, Explore, Plan, Execute, Validate.</li> <li>Cross-Repository Coordination -- Link multiple repos, coordinate commits, and enforce permission boundaries.</li> <li>Adopt Existing Repos -- Transform any GitHub repo into a ricet project with <code>ricet adopt</code>, including fork, scaffold, and GOAL pre-fill from README.</li> <li>Cross-Repo RAG -- Link external repositories with <code>ricet link</code> so agents can search across all your code while only editing the current project.</li> <li>Auto-Commit &amp; Push -- Every state-modifying command automatically commits and pushes, controlled by environment variables.</li> <li>Collaborative Research -- Multiple researchers on the same repo with auto-sync, user attribution, and merge-friendly append-only files.</li> <li>Claude-Powered Intelligence -- Seven core modules use Claude CLI for intelligent routing, debugging, and suggestions with keyword fallback.</li> <li>Literature Search -- <code>ricet cite</code> and <code>ricet discover</code> search Semantic Scholar and arXiv, format BibTeX, and append to your bibliography.</li> <li>Style Transfer -- <code>ricet paper adapt-style</code> rewrites your paper to match a reference paper's writing style with plagiarism checks.</li> <li>Auto Test Generation -- <code>ricet test-gen</code> scans for uncovered source files and generates pytest stubs using Claude.</li> <li>Package Management -- <code>ricet package init/build/publish</code> turns research code into reusable Python packages.</li> <li>Daily Maintenance -- <code>ricet maintain</code> runs test generation, docs update, fidelity check, and verification in one pass. Auto-runs after overnight sessions.</li> <li>Goal Fidelity -- <code>ricet fidelity</code> scores alignment between the codebase and GOAL.md, flagging drift areas.</li> <li>Cross-Project Learning -- <code>ricet sync-learnings</code> shares encyclopedia entries across ricet projects.</li> <li>MCP Discovery -- <code>ricet mcp-search</code> searches 1300+ MCP servers and installs on demand.</li> <li>Dual-Repo Structure -- <code>ricet two-repo</code> manages experiments/ vs clean/ separation with promotion gates.</li> <li>URL Browsing -- <code>ricet browse</code> fetches and extracts text from URLs for literature review.</li> <li>Infrastructure -- <code>ricet infra</code> handles Docker builds, CI/CD, secrets, and dependency checks.</li> <li>Runbook Execution -- <code>ricet runbook</code> parses and executes code blocks from markdown runbooks.</li> <li>Docker Overnight -- <code>ricet overnight --docker</code> runs autonomous sessions inside a Docker sandbox.</li> <li>Resource-Aware Overnight -- Monitors CPU/RAM/disk between iterations, auto-pauses on low resources.</li> <li>Falsifier Auto-Trigger -- Falsifier agent validates results after every overnight iteration automatically.</li> <li>Voice Prompting -- <code>ricet voice</code> transcribes audio instructions and structures them into actionable research prompts.</li> <li>Mobile PWA -- <code>ricet mobile</code> sets up Progressive Web App access for remote monitoring.</li> <li>Interactive Dashboard -- <code>ricet dashboard</code> provides a Rich TUI with live agent status, budget, and resource utilization.</li> <li>Figure Gallery -- <code>ricet gallery</code> scans and catalogs experiment figures by run ID for quick review and paper inclusion.</li> <li>Git Worktree Management -- <code>ricet worktree</code> manages parallel branches for concurrent experiments.</li> <li>Task Queue -- <code>ricet queue</code> manages and spools background tasks for batch execution.</li> <li>Website Builder -- <code>ricet website</code> generates and deploys a GitHub Pages documentation site.</li> <li>RAG-Powered MCP Discovery -- Searchable index of 1300+ MCP servers with keyword-based suggestion and on-demand installation.</li> <li>PaperBoat -- Recommended external service for daily cross-discipline paper discovery. Useful as a background SOTA knowledge source that updates daily.</li> </ul> <p>Explore all features in the Features page.</p>"},{"location":"#project-philosophy","title":"Project Philosophy","text":"<p>ricet is built on six core principles:</p> <ol> <li>Never please the user -- Be objective, challenge assumptions, report flaws.</li> <li>Popperian falsification -- Try to break results, not validate them.</li> <li>Never guess -- Search or ask when uncertain.</li> <li>Test small, then scale -- Downsample first, run one epoch, then scale up.</li> <li>Commit aggressively -- Meaningful commits after every subtask.</li> <li>Accumulate knowledge -- The encyclopedia grows with every task.</li> </ol>"},{"location":"#project-status","title":"Project Status","text":"<p>ricet is under active development. The core modules, CLI, Docker setup, templates, and agent system are implemented. Contributions and feedback are welcome.</p> Component Status CLI (<code>ricet</code> command) Implemented Core modules (45+ modules) Implemented Docker containerization Implemented Agent orchestration Implemented Paper pipeline Implemented MCP auto-discovery (70+) Implemented claude-flow integration Implemented (optional) GitHub workflows Implemented Voice &amp; mobile access Implemented Interactive dashboard &amp; gallery Implemented Documentation site You are here"},{"location":"#about","title":"About","text":"<p>ricet is designed and maintained by Luca Fusar Bassini.</p>"},{"location":"#license","title":"License","text":"<p>MIT</p>"},{"location":"api/","title":"API Reference","text":"<p>Module-level documentation for all core packages. Each section covers public classes, functions, and constants.</p>"},{"location":"api/#climain-cli-entry-point","title":"<code>cli.main</code> -- CLI Entry Point","text":"<p>The main Typer application providing the <code>ricet</code> command.</p>"},{"location":"api/#commands","title":"Commands","text":"Command Description <code>ricetinit &lt;name&gt;</code> Initialize a new research project with interactive onboarding <code>ricetstart</code> Start an interactive research session <code>ricetovernight</code> Run autonomous overnight mode <code>ricetstatus</code> Show current TODO and progress <code>ricetpaper build</code> Compile the LaTeX paper <code>ricetdashboard</code> Launch the TUI dashboard <code>ricetagents</code> List agent types and their status <code>ricetmemory search &lt;query&gt;</code> Search the knowledge base <code>ricetmetrics</code> Display token and cost metrics <code>ricet--version</code> Print version and exit"},{"location":"api/#options","title":"Options","text":"<pre><code>ricet init &lt;name&gt; [--path PATH]\nresearch start [--session-name NAME]\nresearch overnight [--task-file PATH] [--iterations N]\n</code></pre>"},{"location":"api/#clidashboard-tui-dashboard","title":"<code>cli.dashboard</code> -- TUI Dashboard","text":"<p>Rich-based terminal dashboard for monitoring active sessions.</p>"},{"location":"api/#panels","title":"Panels","text":"<ul> <li>Agents -- Active agent types, current tasks, and budget usage.</li> <li>Resources -- CPU, RAM, GPU, and disk utilization.</li> <li>Memory -- Recent knowledge entries and vector memory stats.</li> <li>Progress -- Task completion log.</li> </ul>"},{"location":"api/#cligallery-figure-gallery","title":"<code>cli.gallery</code> -- Figure Gallery","text":"<p>Terminal-based figure preview for generated plots.</p>"},{"location":"api/#coreagents-agent-orchestration","title":"<code>core.agents</code> -- Agent Orchestration","text":"<p>Task routing, budget management, DAG execution, and supervision.</p>"},{"location":"api/#agenttype","title":"<code>AgentType</code>","text":"<pre><code>class AgentType(str, Enum):\n    MASTER = \"master\"\n    RESEARCHER = \"researcher\"\n    CODER = \"coder\"\n    REVIEWER = \"reviewer\"\n    FALSIFIER = \"falsifier\"\n    WRITER = \"writer\"\n    CLEANER = \"cleaner\"\n</code></pre>"},{"location":"api/#constants","title":"Constants","text":"<pre><code>DEFAULT_BUDGET_SPLIT: dict[AgentType, int]\n# {RESEARCHER: 15, CODER: 35, REVIEWER: 10, FALSIFIER: 20, WRITER: 15, CLEANER: 5}\n\nROUTING_KEYWORDS: dict[AgentType, list[str]]\n# Keyword lists used for automatic task routing.\n</code></pre>"},{"location":"api/#functions","title":"Functions","text":""},{"location":"api/#route_taskdescription-str-agenttype","title":"<code>route_task(description: str) -&gt; AgentType</code>","text":"<p>Classify a task description and return the most appropriate agent type based on keyword matching.</p>"},{"location":"api/#execute_tasktask-task-taskresult","title":"<code>execute_task(task: Task) -&gt; TaskResult</code>","text":"<p>Execute a single task. Delegates to claude-flow <code>spawn_agent</code> when available, otherwise calls Claude CLI as a subprocess.</p>"},{"location":"api/#execute_dagtasks-listtask-listtaskresult","title":"<code>execute_dag(tasks: list[Task]) -&gt; list[TaskResult]</code>","text":"<p>Execute a DAG of tasks, resolving dependencies and running independent tasks in parallel via <code>ThreadPoolExecutor</code>. Falls back from claude-flow <code>run_swarm</code> when unavailable.</p>"},{"location":"api/#coresession-session-management","title":"<code>core.session</code> -- Session Management","text":"<p>Tracking, snapshots, and recovery for research sessions.</p>"},{"location":"api/#session","title":"<code>Session</code>","text":"<pre><code>@dataclass\nclass Session:\n    name: str\n    started: str                    # ISO timestamp\n    status: str = \"active\"          # \"active\" | \"completed\"\n    token_estimate: int = 0\n    tasks_completed: int = 0\n    tasks_failed: int = 0\n    checkpoints: list[str] = field(default_factory=list)\n\n    def to_dict(self) -&gt; dict: ...\n    @classmethod\n    def from_dict(cls, data: dict) -&gt; Session: ...\n</code></pre>"},{"location":"api/#functions_1","title":"Functions","text":""},{"location":"api/#create_sessionname-optionalstr-none-session","title":"<code>create_session(name: Optional[str] = None) -&gt; Session</code>","text":"<p>Create and persist a new session. Also starts a claude-flow session when available.</p>"},{"location":"api/#end_sessionname-str-session","title":"<code>end_session(name: str) -&gt; Session</code>","text":"<p>Mark a session as completed and update the JSON file.</p>"},{"location":"api/#get_sessionname-str-optionalsession","title":"<code>get_session(name: str) -&gt; Optional[Session]</code>","text":"<p>Load a session by name.</p>"},{"location":"api/#list_sessions-listsession","title":"<code>list_sessions() -&gt; list[Session]</code>","text":"<p>Return all persisted sessions.</p>"},{"location":"api/#create_snapshotsession-session-path","title":"<code>create_snapshot(session: Session) -&gt; Path</code>","text":"<p>Save a copy of the current state directory for recovery.</p>"},{"location":"api/#coretokens-token-budget-tracking","title":"<code>core.tokens</code> -- Token Budget Tracking","text":"<p>Token estimation and budget management with claude-flow metrics integration.</p>"},{"location":"api/#tokenbudget","title":"<code>TokenBudget</code>","text":"<pre><code>@dataclass\nclass TokenBudget:\n    session_limit: int = 100_000\n    daily_limit: int = 500_000\n    current_session: int = 0\n    current_daily: int = 0\n</code></pre>"},{"location":"api/#functions_2","title":"Functions","text":""},{"location":"api/#estimate_tokenstext-str-int","title":"<code>estimate_tokens(text: str) -&gt; int</code>","text":"<p>Estimate token count. Uses claude-flow metrics for actual counts when available, otherwise approximates at ~4 characters per token.</p>"},{"location":"api/#check_budgetbudget-tokenbudget-estimated_cost-int-dict","title":"<code>check_budget(budget: TokenBudget, estimated_cost: int) -&gt; dict</code>","text":"<p>Check whether an operation fits within budget. Returns:</p> <pre><code>{\n    \"can_proceed\": bool,\n    \"session_used_pct\": float,\n    \"daily_used_pct\": float,\n    \"warning\": bool,       # True when session usage &gt; 75%\n}\n</code></pre>"},{"location":"api/#select_thinking_modetask_description-str-str","title":"<code>select_thinking_mode(task_description: str) -&gt; str</code>","text":"<p>Auto-select thinking mode based on task complexity. Returns one of: <code>\"none\"</code>, <code>\"standard\"</code>, <code>\"extended\"</code>, <code>\"ultrathink\"</code>.</p>"},{"location":"api/#coreknowledge-knowledge-management","title":"<code>core.knowledge</code> -- Knowledge Management","text":"<p>Encyclopedia auto-update and semantic search.</p>"},{"location":"api/#constants_1","title":"Constants","text":"<pre><code>ENCYCLOPEDIA_PATH = Path(\"knowledge/ENCYCLOPEDIA.md\")\nSHARED_KNOWLEDGE_PATH = Path(\"/shared/knowledge\")\n</code></pre>"},{"location":"api/#functions_3","title":"Functions","text":""},{"location":"api/#append_learningsection-str-entry-str-encyclopedia_path-path-encyclopedia_path-none","title":"<code>append_learning(section: str, entry: str, encyclopedia_path: Path = ENCYCLOPEDIA_PATH) -&gt; None</code>","text":"<p>Append a timestamped entry to the encyclopedia under the given section. Valid sections: <code>\"Tricks\"</code>, <code>\"Decisions\"</code>, <code>\"What Works\"</code>, <code>\"What Doesn't Work\"</code>.</p> <p>When claude-flow is available, the entry is also written to the HNSW vector index.</p>"},{"location":"api/#search_knowledgequery-str-top_k-int-5-liststr","title":"<code>search_knowledge(query: str, top_k: int = 5) -&gt; list[str]</code>","text":"<p>Search the knowledge base. Uses HNSW semantic search via claude-flow when available, otherwise performs keyword grep over the markdown file.</p>"},{"location":"api/#sync_shared_knowledgeproject_path-path-none","title":"<code>sync_shared_knowledge(project_path: Path) -&gt; None</code>","text":"<p>Sync knowledge entries to the shared volume for cross-project access.</p>"},{"location":"api/#coremcps-mcp-auto-discovery","title":"<code>core.mcps</code> -- MCP Auto-Discovery","text":"<p>Task-based MCP tier loading.</p>"},{"location":"api/#constants_2","title":"Constants","text":"<pre><code>MCP_CONFIG = Path(\"templates/config/mcp-nucleus.json\")\n</code></pre>"},{"location":"api/#functions_4","title":"Functions","text":""},{"location":"api/#load_mcp_config-dict","title":"<code>load_mcp_config() -&gt; dict</code>","text":"<p>Load the full MCP tier configuration from JSON.</p>"},{"location":"api/#classify_tasktask_description-str-setstr","title":"<code>classify_task(task_description: str) -&gt; set[str]</code>","text":"<p>Determine which MCP tiers to load based on keyword matching. Always includes <code>\"tier1_essential\"</code>.</p>"},{"location":"api/#get_mcps_for_tasktask_description-str-dict","title":"<code>get_mcps_for_task(task_description: str) -&gt; dict</code>","text":"<p>Return all MCPs needed for a task by merging the relevant tiers.</p>"},{"location":"api/#get_claude_flow_mcp_config-dict","title":"<code>get_claude_flow_mcp_config() -&gt; dict</code>","text":"<p>Return claude-flow as a tier-0 MCP entry when available, or an empty dict.</p>"},{"location":"api/#install_mcpmcp_name-str-source-str-bool","title":"<code>install_mcp(mcp_name: str, source: str) -&gt; bool</code>","text":"<p>Install an MCP from its source (GitHub or npm).</p>"},{"location":"api/#coremodel_router-model-routing","title":"<code>core.model_router</code> -- Model Routing","text":"<p>Task complexity classification and model selection.</p>"},{"location":"api/#taskcomplexity","title":"<code>TaskComplexity</code>","text":"<pre><code>class TaskComplexity(str, Enum):\n    SIMPLE = \"simple\"\n    MEDIUM = \"medium\"\n    COMPLEX = \"complex\"\n    CRITICAL = \"critical\"\n</code></pre>"},{"location":"api/#modelconfig","title":"<code>ModelConfig</code>","text":"<pre><code>@dataclass\nclass ModelConfig:\n    name: str\n    provider: str                  # \"anthropic\", \"openai\", \"local\"\n    max_tokens: int = 4096\n    cost_per_1k_input: float = 0.0\n    cost_per_1k_output: float = 0.0\n    supports_thinking: bool = False\n    strengths: list[str] = field(default_factory=list)\n</code></pre>"},{"location":"api/#functions_5","title":"Functions","text":""},{"location":"api/#classify_complexitydescription-str-taskcomplexity","title":"<code>classify_complexity(description: str) -&gt; TaskComplexity</code>","text":"<p>Classify task complexity using keyword sets. Delegates to claude-flow 3-tier router when available.</p>"},{"location":"api/#select_modelcomplexity-taskcomplexity-budget-optionaltokenbudget-none-modelconfig","title":"<code>select_model(complexity: TaskComplexity, budget: Optional[TokenBudget] = None) -&gt; ModelConfig</code>","text":"<p>Select the appropriate model for a given complexity level. When budget is below 20%, always returns Haiku.</p>"},{"location":"api/#corepaper-paper-pipeline","title":"<code>core.paper</code> -- Paper Pipeline","text":"<p>Figure generation, citation management, and LaTeX compilation.</p>"},{"location":"api/#constants_3","title":"Constants","text":"<pre><code>PAPER_DIR = Path(\"paper\")\nFIGURES_DIR = Path(\"figures\")\nBIB_FILE = PAPER_DIR / \"references.bib\"\n\nCOLORS: dict[str, str]   # Colorblind-safe hex palette\nRC_PARAMS: dict           # matplotlib rcParams for publication quality\n</code></pre>"},{"location":"api/#functions_6","title":"Functions","text":""},{"location":"api/#apply_rcparams-none","title":"<code>apply_rcparams() -&gt; None</code>","text":"<p>Apply publication-quality matplotlib rcParams globally.</p>"},{"location":"api/#add_citationkey-str-entry_type-str-article-author-str-title-str-year-str-kwargs-none","title":"<code>add_citation(key: str, entry_type: str = \"article\", *, author: str, title: str, year: str, **kwargs) -&gt; None</code>","text":"<p>Add a BibTeX entry to <code>references.bib</code>. Supports all standard BibTeX fields (<code>journal</code>, <code>doi</code>, <code>volume</code>, <code>pages</code>, etc.).</p>"},{"location":"api/#compile_paperpaper_dir-path-paper_dir-bool","title":"<code>compile_paper(paper_dir: Path = PAPER_DIR) -&gt; bool</code>","text":"<p>Run the full LaTeX build: <code>pdflatex</code> -&gt; <code>biber</code> -&gt; <code>pdflatex</code> -&gt; <code>pdflatex</code>.</p>"},{"location":"api/#list_figuresfigures_dir-path-figures_dir-listpath","title":"<code>list_figures(figures_dir: Path = FIGURES_DIR) -&gt; list[Path]</code>","text":"<p>List all generated figures.</p>"},{"location":"api/#corereproducibility-reproducibility","title":"<code>core.reproducibility</code> -- Reproducibility","text":"<p>Run logging, artifact registry, and dataset hashing.</p>"},{"location":"api/#runlog","title":"<code>RunLog</code>","text":"<pre><code>@dataclass\nclass RunLog:\n    run_id: str\n    command: str\n    started: str                    # ISO timestamp\n    ended: Optional[str] = None\n    status: str = \"running\"\n    git_hash: str = \"\"\n    parameters: dict = field(default_factory=dict)\n    metrics: dict = field(default_factory=dict)\n    artifacts: list[str] = field(default_factory=list)\n    notes: str = \"\"\n</code></pre>"},{"location":"api/#functions_7","title":"Functions","text":""},{"location":"api/#log_runrun-runlog-path","title":"<code>log_run(run: RunLog) -&gt; Path</code>","text":"<p>Persist a run log to <code>state/runs/&lt;run_id&gt;.json</code>.</p>"},{"location":"api/#load_runrun_id-str-optionalrunlog","title":"<code>load_run(run_id: str) -&gt; Optional[RunLog]</code>","text":"<p>Load a run log by ID.</p>"},{"location":"api/#register_artifactname-str-path-str-run_id-str-metadata-dict-none","title":"<code>register_artifact(name: str, path: str, run_id: str, metadata: dict = {}) -&gt; None</code>","text":"<p>Register an artifact with SHA-256 checksum in <code>state/artifact_registry.json</code>.</p>"},{"location":"api/#verify_artifactname-str-bool","title":"<code>verify_artifact(name: str) -&gt; bool</code>","text":"<p>Verify an artifact's integrity by recomputing its checksum.</p>"},{"location":"api/#hash_datasetpath-path-str","title":"<code>hash_dataset(path: Path) -&gt; str</code>","text":"<p>Compute a SHA-256 hash of a dataset file for integrity tracking.</p>"},{"location":"api/#coresecurity-security","title":"<code>core.security</code> -- Security","text":"<p>Secret scanning, immutable file protection, and repo root enforcement.</p>"},{"location":"api/#constants_4","title":"Constants","text":"<pre><code>SECRET_PATTERNS: list[re.Pattern]   # Regex patterns for secret detection\nDEFAULT_IMMUTABLE: list[str]        # Glob patterns for immutable files\n</code></pre>"},{"location":"api/#functions_8","title":"Functions","text":""},{"location":"api/#enforce_repo_root-path","title":"<code>enforce_repo_root() -&gt; Path</code>","text":"<p>Ensure the current directory is inside a git repository. Returns the repo root path. Raises <code>RuntimeError</code> if not in a repo.</p>"},{"location":"api/#scan_for_secretspath-path-extra_patterns-listrepattern-none-none-listdict","title":"<code>scan_for_secrets(path: Path, *, extra_patterns: list[re.Pattern] | None = None) -&gt; list[dict]</code>","text":"<p>Scan files for secrets. Merges claude-flow scan results with local regex matches when available. Returns a list of findings with file path, line number, and matched pattern.</p>"},{"location":"api/#protect_immutable_filesfiles-liststr-liststr","title":"<code>protect_immutable_files(files: list[str]) -&gt; list[str]</code>","text":"<p>Filter out immutable files from a list of paths. Returns only the files that are safe to modify.</p>"},{"location":"api/#corenotifications-notifications","title":"<code>core.notifications</code> -- Notifications","text":"<p>Multi-channel notifications with throttling.</p>"},{"location":"api/#notificationconfig","title":"<code>NotificationConfig</code>","text":"<pre><code>@dataclass\nclass NotificationConfig:\n    slack_webhook: str = \"\"\n    email_to: str = \"\"\n    email_from: str = \"\"\n    smtp_host: str = \"smtp.gmail.com\"\n    smtp_port: int = 587\n    smtp_user: str = \"\"\n    smtp_password: str = \"\"\n    desktop_enabled: bool = True\n    throttle_seconds: int = 300\n</code></pre>"},{"location":"api/#functions_9","title":"Functions","text":""},{"location":"api/#send_notificationmessage-str-title-str-level-str-info-none","title":"<code>send_notification(message: str, *, title: str = \"\", level: str = \"info\") -&gt; None</code>","text":"<p>Send a notification to all configured channels. Respects throttle settings.</p>"},{"location":"api/#send_slackmessage-str-webhook_url-str-bool","title":"<code>send_slack(message: str, webhook_url: str) -&gt; bool</code>","text":"<p>Send a Slack message via webhook.</p>"},{"location":"api/#send_emailsubject-str-body-str-config-notificationconfig-bool","title":"<code>send_email(subject: str, body: str, config: NotificationConfig) -&gt; bool</code>","text":"<p>Send an email via SMTP.</p>"},{"location":"api/#send_desktoptitle-str-message-str-bool","title":"<code>send_desktop(title: str, message: str) -&gt; bool</code>","text":"<p>Send a desktop notification via <code>notify-send</code>.</p>"},{"location":"api/#coreenvironment-environment-management","title":"<code>core.environment</code> -- Environment Management","text":"<p>System discovery and conda environment management.</p>"},{"location":"api/#systeminfo","title":"<code>SystemInfo</code>","text":"<pre><code>@dataclass\nclass SystemInfo:\n    os: str = \"\"\n    os_version: str = \"\"\n    python_version: str = \"\"\n    cpu: str = \"\"\n    gpu: str = \"\"\n    ram_gb: float = 0.0\n    conda_available: bool = False\n    docker_available: bool = False\n</code></pre>"},{"location":"api/#functions_10","title":"Functions","text":""},{"location":"api/#discover_system-systeminfo","title":"<code>discover_system() -&gt; SystemInfo</code>","text":"<p>Detect the current system's hardware and software capabilities.</p>"},{"location":"api/#create_conda_envname-str-python_version-str-311-bool","title":"<code>create_conda_env(name: str, python_version: str = \"3.11\") -&gt; bool</code>","text":"<p>Create a new conda environment.</p>"},{"location":"api/#install_packagespackages-liststr-env_name-optionalstr-none-bool","title":"<code>install_packages(packages: list[str], env_name: Optional[str] = None) -&gt; bool</code>","text":"<p>Install packages into a conda environment or the current Python environment.</p>"},{"location":"api/#coreresources-resource-monitoring","title":"<code>core.resources</code> -- Resource Monitoring","text":"<p>Resource snapshots, checkpoint policies, and cleanup.</p>"},{"location":"api/#resourcesnapshot","title":"<code>ResourceSnapshot</code>","text":"<pre><code>@dataclass\nclass ResourceSnapshot:\n    timestamp: float = 0.0\n    cpu_percent: float = 0.0\n    ram_used_gb: float = 0.0\n    ram_total_gb: float = 0.0\n    disk_free_gb: float = 0.0\n    gpu_memory_used_mb: float = 0.0\n    gpu_memory_total_mb: float = 0.0\n</code></pre>"},{"location":"api/#checkpointpolicy","title":"<code>CheckpointPolicy</code>","text":"<pre><code>@dataclass\nclass CheckpointPolicy:\n    interval_minutes: int = 30\n    max_checkpoints: int = 5\n    min_disk_free_gb: float = 5.0\n    checkpoint_dir: Path = CHECKPOINTS_DIR\n</code></pre>"},{"location":"api/#functions_11","title":"Functions","text":""},{"location":"api/#monitor_resources-resourcesnapshot","title":"<code>monitor_resources() -&gt; ResourceSnapshot</code>","text":"<p>Take a snapshot of current system resource usage. Merges claude-flow GPU metrics when available.</p>"},{"location":"api/#should_checkpointpolicy-checkpointpolicy-last_checkpoint_time-float-bool","title":"<code>should_checkpoint(policy: CheckpointPolicy, last_checkpoint_time: float) -&gt; bool</code>","text":"<p>Determine whether a new checkpoint should be created based on the policy.</p>"},{"location":"api/#create_checkpointname-str-policy-checkpointpolicy-path","title":"<code>create_checkpoint(name: str, policy: CheckpointPolicy) -&gt; Path</code>","text":"<p>Create a checkpoint of the current state, respecting retention limits.</p>"},{"location":"api/#cleanup_old_checkpointspolicy-checkpointpolicy-int","title":"<code>cleanup_old_checkpoints(policy: CheckpointPolicy) -&gt; int</code>","text":"<p>Remove checkpoints exceeding the maximum count. Returns the number removed.</p>"},{"location":"api/#coreonboarding-project-initialization","title":"<code>core.onboarding</code> -- Project Initialization","text":"<p>Interactive onboarding questionnaire and workspace setup.</p>"},{"location":"api/#onboardinganswers","title":"<code>OnboardingAnswers</code>","text":"<p>Dataclass holding all user responses from the init wizard: project goal, type, timeline, constraints, and credentials.</p>"},{"location":"api/#functions_12","title":"Functions","text":""},{"location":"api/#collect_answers-onboardinganswers","title":"<code>collect_answers() -&gt; OnboardingAnswers</code>","text":"<p>Run the interactive questionnaire and return structured answers.</p>"},{"location":"api/#setup_workspaceproject_path-path-answers-onboardinganswers-none","title":"<code>setup_workspace(project_path: Path, answers: OnboardingAnswers) -&gt; None</code>","text":"<p>Create the project directory structure from templates.</p>"},{"location":"api/#write_goal_filepath-path-answers-onboardinganswers-none","title":"<code>write_goal_file(path: Path, answers: OnboardingAnswers) -&gt; None</code>","text":"<p>Write the customized GOAL.md.</p>"},{"location":"api/#write_settingspath-path-answers-onboardinganswers-none","title":"<code>write_settings(path: Path, answers: OnboardingAnswers) -&gt; None</code>","text":"<p>Write <code>config/settings.yml</code> from onboarding answers.</p>"},{"location":"api/#coreautonomous-autonomous-routines","title":"<code>core.autonomous</code> -- Autonomous Routines","text":"<p>Scheduled tasks, monitoring, and confirmation gates.</p>"},{"location":"api/#scheduledroutine","title":"<code>ScheduledRoutine</code>","text":"<pre><code>@dataclass\nclass ScheduledRoutine:\n    name: str\n    description: str\n    schedule: str                  # \"daily\", \"hourly\", \"weekly\", or cron\n    command: str\n    enabled: bool = True\n    last_run: str = \"\"\n    requires_confirmation: bool = False\n</code></pre>"},{"location":"api/#functions_13","title":"Functions","text":""},{"location":"api/#add_routineroutine-scheduledroutine-none","title":"<code>add_routine(routine: ScheduledRoutine) -&gt; None</code>","text":"<p>Register a new scheduled routine.</p>"},{"location":"api/#remove_routinename-str-bool","title":"<code>remove_routine(name: str) -&gt; bool</code>","text":"<p>Remove a routine by name.</p>"},{"location":"api/#list_routines-listscheduledroutine","title":"<code>list_routines() -&gt; list[ScheduledRoutine]</code>","text":"<p>List all registered routines.</p>"},{"location":"api/#run_due_routines-liststr","title":"<code>run_due_routines() -&gt; list[str]</code>","text":"<p>Execute all routines that are due. Returns names of executed routines. Routines requiring confirmation are skipped in autonomous mode.</p>"},{"location":"api/#audit_logaction-str-details-str-none","title":"<code>audit_log(action: str, details: str = \"\") -&gt; None</code>","text":"<p>Append an entry to <code>state/audit.log</code>.</p>"},{"location":"api/#coreauto_commit-auto-commit-push","title":"<code>core.auto_commit</code> -- Auto-Commit &amp; Push","text":"<p>Automatic git commit and push after state-modifying operations.</p>"},{"location":"api/#functions_14","title":"Functions","text":""},{"location":"api/#auto_commitmessage-str-push-bool-none-none-cwd-path-none-none-run_cmdnone-bool","title":"<code>auto_commit(message: str, *, push: bool | None = None, cwd: Path | None = None, run_cmd=None) -&gt; bool</code>","text":"<p>Commit all changes and optionally push. Controlled by environment variables:</p> <ul> <li><code>RICET_AUTO_COMMIT</code> (default <code>\"true\"</code>) -- master switch</li> <li><code>AUTO_PUSH</code> (default <code>\"true\"</code>) -- push after commit</li> </ul> <p>Returns <code>True</code> if a commit was made, <code>False</code> otherwise (no changes, not a git repo, or disabled).</p>"},{"location":"api/#coreclaude_helper-claude-cli-helper","title":"<code>core.claude_helper</code> -- Claude CLI Helper","text":"<p>Shared helper for calling the Claude CLI from core modules.</p>"},{"location":"api/#functions_15","title":"Functions","text":""},{"location":"api/#call_claudeprompt-str-timeout-int-30-run_cmdnone-str-none","title":"<code>call_claude(prompt: str, *, timeout: int = 30, run_cmd=None) -&gt; str | None</code>","text":"<p>Call <code>claude -p &lt;prompt&gt; --output-format json</code> and return the response text. Returns <code>None</code> on failure, timeout, or when disabled.</p>"},{"location":"api/#call_claude_jsonprompt-str-kwargs-dict-list-none","title":"<code>call_claude_json(prompt: str, **kwargs) -&gt; dict | list | None</code>","text":"<p>Call Claude and parse the response as JSON. Strips markdown code fences before parsing. Returns <code>None</code> if parsing fails.</p>"},{"location":"api/#configuration","title":"Configuration","text":"<ul> <li><code>RICET_NO_CLAUDE=true</code> -- Disable all Claude CLI calls</li> <li>Auto-disabled during pytest (<code>PYTEST_CURRENT_TEST</code> detection)</li> </ul>"},{"location":"api/#coreadopt-repository-adoption","title":"<code>core.adopt</code> -- Repository Adoption","text":"<p>Transform existing repositories into ricet projects.</p>"},{"location":"api/#functions_16","title":"Functions","text":""},{"location":"api/#adopt_reposource-str-project_name-str-none-none-target_path-path-none-none-fork-bool-true-run_cmdnone-path","title":"<code>adopt_repo(source: str, *, project_name: str | None = None, target_path: Path | None = None, fork: bool = True, run_cmd=None) -&gt; Path</code>","text":"<p>Adopt a repository from a GitHub URL or local path:</p> <ol> <li>URL + fork: <code>gh repo fork --clone</code> (falls back to <code>git clone</code>)</li> <li>URL + no fork: <code>git clone</code></li> <li>Local path: work in place</li> </ol> <p>Overlays ricet structure, pre-fills GOAL.md from README, registers in <code>~/.ricet/projects.json</code>, and auto-commits.</p>"},{"location":"api/#corecollaboration-collaborative-research","title":"<code>core.collaboration</code> -- Collaborative Research","text":"<p>Multi-user synchronization and merge helpers.</p>"},{"location":"api/#functions_17","title":"Functions","text":""},{"location":"api/#sync_before_start-cwd-path-none-none-run_cmdnone-bool","title":"<code>sync_before_start(*, cwd: Path | None = None, run_cmd=None) -&gt; bool</code>","text":"<p>Run <code>git pull --rebase</code> to sync with remote before starting a session. Returns <code>True</code> on success.</p>"},{"location":"api/#get_user_id-run_cmdnone-str","title":"<code>get_user_id(*, run_cmd=None) -&gt; str</code>","text":"<p>Get current user identity from <code>git config user.email</code>, falling back to hostname.</p>"},{"location":"api/#merge_encyclopediaours_path-path-theirs_text-str-str","title":"<code>merge_encyclopedia(ours_path: Path, theirs_text: str) -&gt; str</code>","text":"<p>Merge encyclopedia content by deduplicating lines.</p>"},{"location":"api/#merge_state_fileours_path-path-theirs_text-str-str","title":"<code>merge_state_file(ours_path: Path, theirs_text: str) -&gt; str</code>","text":"<p>Merge state files by appending non-duplicate non-empty lines.</p>"},{"location":"api/#corecross_repo-cross-repository-coordination-rag","title":"<code>core.cross_repo</code> -- Cross-Repository Coordination &amp; RAG","text":"<p>Linking repos, coordinated commits, permission management, and cross-repo RAG indexing.</p>"},{"location":"api/#linkedrepo","title":"<code>LinkedRepo</code>","text":"<pre><code>@dataclass\nclass LinkedRepo:\n    name: str\n    path: str\n    remote_url: str = \"\"\n    permissions: list[str] = field(default_factory=lambda: [\"read\"])\n    linked_at: str                 # ISO timestamp\n</code></pre>"},{"location":"api/#functions_18","title":"Functions","text":""},{"location":"api/#link_repositoryname-str-path-str-permissions-liststr-read-linkedrepo","title":"<code>link_repository(name: str, path: str, permissions: list[str] = [\"read\"]) -&gt; LinkedRepo</code>","text":"<p>Link an external repository with specified permissions.</p>"},{"location":"api/#coordinated_commitmessage-str-repo_names-liststr-dictstr-bool","title":"<code>coordinated_commit(message: str, repo_names: list[str]) -&gt; dict[str, bool]</code>","text":"<p>Commit to multiple linked repos with the same message. Delegates to claude-flow <code>multi_repo_sync</code> when available. Returns a dict mapping repo names to success status.</p>"},{"location":"api/#index_linked_reporepo-linkedrepo-int","title":"<code>index_linked_repo(repo: LinkedRepo) -&gt; int</code>","text":"<p>Walk a linked repo and index text files (.py, .md, .txt, .tex, .rst, .yml, .yaml, .json) into HNSW vector memory or local JSON. Returns the number of files indexed.</p>"},{"location":"api/#search_all_linkedquery-str-top_k-int-10-listdict","title":"<code>search_all_linked(query: str, top_k: int = 10) -&gt; list[dict]</code>","text":"<p>Search across all linked repo indexes. Uses HNSW semantic search when available, otherwise keyword search on local JSON. Returns dicts with <code>text</code>, <code>path</code>, <code>source</code> keys.</p>"},{"location":"api/#reindex_all-dictstr-int","title":"<code>reindex_all() -&gt; dict[str, int]</code>","text":"<p>Re-index all linked repositories. Returns a dict mapping repo name to file count.</p>"},{"location":"api/#enforce_permission_boundariesrepo_name-str-action-str-bool","title":"<code>enforce_permission_boundaries(repo_name: str, action: str) -&gt; bool</code>","text":"<p>Check if an action (<code>read</code>, <code>write</code>, <code>commit</code>) is permitted on a linked repo.</p>"},{"location":"api/#coreclaude_flow-claude-flow-bridge","title":"<code>core.claude_flow</code> -- Claude-Flow Bridge","text":"<p>Bridge to claude-flow v3 CLI for enhanced orchestration.</p>"},{"location":"api/#claudeflowunavailable","title":"<code>ClaudeFlowUnavailable</code>","text":"<p>Exception raised when claude-flow is not installed or a command fails.</p>"},{"location":"api/#claudeflowbridge","title":"<code>ClaudeFlowBridge</code>","text":"<p>Singleton wrapper around the <code>npx claude-flow@v3alpha</code> CLI.</p> Method Description Fallback <code>spawn_agent(type, task)</code> Execute single agent task Claude CLI subprocess <code>run_swarm(tasks, topology)</code> Multi-agent swarm execution ThreadPoolExecutor <code>route_model(description)</code> 3-tier model routing Keyword classification <code>query_memory(query)</code> HNSW semantic search Keyword grep <code>store_memory(text)</code> Index in vector memory Markdown append <code>scan_security(path)</code> Security scan Local regex patterns <code>get_metrics()</code> Token/cost metrics Char-based estimation <code>start_session(name)</code> Start tracked session Local JSON file <code>end_session(name)</code> End tracked session Local JSON update <code>multi_repo_sync(msg, repos)</code> Cross-repo commit Sequential git commands"},{"location":"api/#functions_19","title":"Functions","text":""},{"location":"api/#_get_bridge-claudeflowbridge","title":"<code>_get_bridge() -&gt; ClaudeFlowBridge</code>","text":"<p>Get or create the singleton bridge instance. Raises <code>ClaudeFlowUnavailable</code> if claude-flow is not installed.</p>"},{"location":"api/#corestyle_transfer-style-transfer","title":"<code>core.style_transfer</code> -- Style Transfer","text":"<p>Paper style analysis and plagiarism checking.</p>"},{"location":"api/#functions_20","title":"Functions","text":""},{"location":"api/#analyze_styletext-str-dict","title":"<code>analyze_style(text: str) -&gt; dict</code>","text":"<p>Analyze the writing style of a text passage (sentence length, vocabulary complexity, passive voice ratio, etc.).</p>"},{"location":"api/#transfer_stylesource_style-dict-text-str-str","title":"<code>transfer_style(source_style: dict, text: str) -&gt; str</code>","text":"<p>Rewrite text to match the analyzed style profile.</p>"},{"location":"api/#check_plagiarismtext-str-reference-str-float","title":"<code>check_plagiarism(text: str, reference: str) -&gt; float</code>","text":"<p>Compute a similarity score between two texts. Returns a float between 0.0 and 1.0.</p>"},{"location":"api/#corevoice-voice-input","title":"<code>core.voice</code> -- Voice Input","text":"<p>Audio transcription and prompt structuring.</p>"},{"location":"api/#functions_21","title":"Functions","text":""},{"location":"api/#transcribe_audioaudio_path-path-str","title":"<code>transcribe_audio(audio_path: Path) -&gt; str</code>","text":"<p>Transcribe an audio file to text using whisper-cpp or a similar backend.</p>"},{"location":"api/#structure_promptraw_text-str-str","title":"<code>structure_prompt(raw_text: str) -&gt; str</code>","text":"<p>Convert raw transcribed text into a structured research prompt.</p>"},{"location":"api/#coremeta_rules-meta-rule-capture","title":"<code>core.meta_rules</code> -- Meta-Rule Capture","text":"<p>Operational rule detection from conversation patterns.</p>"},{"location":"api/#functions_22","title":"Functions","text":""},{"location":"api/#detect_rulesconversation-str-liststr","title":"<code>detect_rules(conversation: str) -&gt; list[str]</code>","text":"<p>Analyze a conversation transcript and extract implicit operational rules.</p>"},{"location":"api/#suggest_rulesdetected-liststr-liststr","title":"<code>suggest_rules(detected: list[str]) -&gt; list[str]</code>","text":"<p>Filter and rank detected rules by relevance.</p>"},{"location":"api/#coreautomation_utils-automation-utilities","title":"<code>core.automation_utils</code> -- Automation Utilities","text":"<p>Data handling and experiment running helpers.</p>"},{"location":"api/#functions_23","title":"Functions","text":""},{"location":"api/#downsampledata-fraction-float-01","title":"<code>downsample(data, fraction: float = 0.1)</code>","text":"<p>Take a random subsample for quick testing.</p>"},{"location":"api/#run_experimentcommand-str-params-dict-runlog","title":"<code>run_experiment(command: str, params: dict) -&gt; RunLog</code>","text":"<p>Execute an experiment command with parameter tracking.</p>"},{"location":"api/#coreauto_debug-auto-debug-loop","title":"<code>core.auto_debug</code> -- Auto-Debug Loop","text":"<p>Automatic error detection, diagnosis, and fix application.</p>"},{"location":"api/#functions_24","title":"Functions","text":""},{"location":"api/#capture_erroroutput-str-dict-none","title":"<code>capture_error(output: str) -&gt; dict | None</code>","text":"<p>Parse command output for errors. Returns a dict with <code>error_type</code>, <code>message</code>, and <code>traceback</code> if an error is found.</p>"},{"location":"api/#suggest_fixerror_info-dict-str","title":"<code>suggest_fix(error_info: dict) -&gt; str</code>","text":"<p>Generate a one-sentence fix suggestion using Claude CLI (falls back to pattern matching).</p>"},{"location":"api/#apply_fixfix-str-file_path-path-bool","title":"<code>apply_fix(fix: str, file_path: Path) -&gt; bool</code>","text":"<p>Apply a suggested fix to the specified file.</p>"},{"location":"api/#debug_loopcommand-str-max_retries-int-3-bool","title":"<code>debug_loop(command: str, max_retries: int = 3) -&gt; bool</code>","text":"<p>Run a command, detect errors, suggest fixes, apply them, and retry. Returns <code>True</code> if the command eventually succeeds.</p>"},{"location":"api/#corebrowser-browser-automation","title":"<code>core.browser</code> -- Browser Automation","text":"<p>Headless browser sessions for web interaction.</p>"},{"location":"api/#functions_25","title":"Functions","text":""},{"location":"api/#browse_urlurl-str-str","title":"<code>browse_url(url: str) -&gt; str</code>","text":"<p>Fetch and extract readable text from a URL. Uses Puppeteer MCP when available, falls back to HTTP fetch.</p>"},{"location":"api/#take_screenshoturl-str-output_path-path-path","title":"<code>take_screenshot(url: str, output_path: Path) -&gt; Path</code>","text":"<p>Capture a screenshot of a URL.</p>"},{"location":"api/#generate_pdfurl-str-output_path-path-path","title":"<code>generate_pdf(url: str, output_path: Path) -&gt; Path</code>","text":"<p>Generate a PDF from a web page.</p>"},{"location":"api/#corevoice-voice-input_1","title":"<code>core.voice</code> -- Voice Input","text":"<p>Audio transcription and prompt structuring.</p>"},{"location":"api/#functions_26","title":"Functions","text":""},{"location":"api/#transcribe_audioaudio_path-path-str_1","title":"<code>transcribe_audio(audio_path: Path) -&gt; str</code>","text":"<p>Transcribe an audio file to text using whisper-cpp or a compatible backend.</p>"},{"location":"api/#detect_languageaudio_path-path-str","title":"<code>detect_language(audio_path: Path) -&gt; str</code>","text":"<p>Detect the language of an audio file.</p>"},{"location":"api/#structure_promptraw_text-str-str_1","title":"<code>structure_prompt(raw_text: str) -&gt; str</code>","text":"<p>Convert raw transcribed text into a structured research prompt.</p>"},{"location":"api/#coremobile-mobile-access","title":"<code>core.mobile</code> -- Mobile Access","text":"<p>Mobile PWA support for remote monitoring.</p>"},{"location":"api/#functions_27","title":"Functions","text":""},{"location":"api/#setup_pwaproject_path-path-dict","title":"<code>setup_pwa(project_path: Path) -&gt; dict</code>","text":"<p>Generate Progressive Web App configuration files for remote access.</p>"},{"location":"api/#generate_manifestproject_name-str-dict","title":"<code>generate_manifest(project_name: str) -&gt; dict</code>","text":"<p>Create a PWA manifest file.</p>"},{"location":"api/#coredoability-task-feasibility","title":"<code>core.doability</code> -- Task Feasibility","text":"<p>Assess whether a task is feasible before committing resources.</p>"},{"location":"api/#functions_28","title":"Functions","text":""},{"location":"api/#assess_doabilitytask-str-dict","title":"<code>assess_doability(task: str) -&gt; dict</code>","text":"<p>Analyze a task description and return a feasibility assessment with score (0-100), risk factors, and recommendations. Uses Claude CLI when available.</p>"},{"location":"api/#coreprompt_suggestions-prompt-suggestions","title":"<code>core.prompt_suggestions</code> -- Prompt Suggestions","text":"<p>AI-powered next-step recommendations.</p>"},{"location":"api/#functions_29","title":"Functions","text":""},{"location":"api/#suggest_next_stepscontext-str-liststr","title":"<code>suggest_next_steps(context: str) -&gt; list[str]</code>","text":"<p>Analyze current project context and suggest the next 3-5 research steps. Uses Claude CLI when available, falls back to template suggestions.</p>"},{"location":"api/#corerag_mcp-rag-mcp-index","title":"<code>core.rag_mcp</code> -- RAG MCP Index","text":"<p>Searchable index of MCP servers for discovery and suggestion.</p>"},{"location":"api/#mcpentry","title":"<code>MCPEntry</code>","text":"<pre><code>@dataclass\nclass MCPEntry:\n    name: str\n    description: str\n    category: str\n    keywords: list[str]\n    install_command: str\n    config_template: dict[str, Any]\n    url: str\n</code></pre>"},{"location":"api/#mcpindex","title":"<code>MCPIndex</code>","text":"<pre><code>class MCPIndex:\n    def build_index(self, entries: list[MCPEntry]) -&gt; None: ...\n    def search(self, query: str, top_k: int = 5) -&gt; list[MCPEntry]: ...\n    def suggest_mcps(self, task_description: str) -&gt; list[MCPEntry]: ...\n    def save_to_json(self, path: Path) -&gt; None: ...\n    def load_from_json(self, path: Path) -&gt; None: ...\n    def install_suggested(self, entries: list[MCPEntry]) -&gt; dict[str, bool]: ...\n</code></pre>"},{"location":"api/#coredevops-infrastructure-management","title":"<code>core.devops</code> -- Infrastructure Management","text":"<p>Docker builds, CI/CD setup, and secrets management.</p>"},{"location":"api/#functions_30","title":"Functions","text":""},{"location":"api/#check_infrastructure-dict","title":"<code>check_infrastructure() -&gt; dict</code>","text":"<p>Verify Docker, CI, and dependency status.</p>"},{"location":"api/#build_docker_imagetag-str-ricetlatest-bool","title":"<code>build_docker_image(tag: str = \"ricet:latest\") -&gt; bool</code>","text":"<p>Build the project Docker image.</p>"},{"location":"api/#manage_secretsaction-str-dict","title":"<code>manage_secrets(action: str) -&gt; dict</code>","text":"<p>Manage project secrets (list, add, remove).</p>"},{"location":"api/#setup_ciprovider-str-github-bool","title":"<code>setup_ci(provider: str = \"github\") -&gt; bool</code>","text":"<p>Generate or update CI workflow files.</p>"},{"location":"api/#corewebsite-website-builder","title":"<code>core.website</code> -- Website Builder","text":"<p>GitHub Pages site generation and deployment.</p>"},{"location":"api/#functions_31","title":"Functions","text":""},{"location":"api/#init_websiteproject_path-path-bool","title":"<code>init_website(project_path: Path) -&gt; bool</code>","text":"<p>Scaffold a MkDocs site with Material theme.</p>"},{"location":"api/#build_websiteproject_path-path-bool","title":"<code>build_website(project_path: Path) -&gt; bool</code>","text":"<p>Build the static site.</p>"},{"location":"api/#deploy_websiteproject_path-path-bool","title":"<code>deploy_website(project_path: Path) -&gt; bool</code>","text":"<p>Deploy to GitHub Pages.</p>"},{"location":"api/#coregit_worktrees-git-worktree-management","title":"<code>core.git_worktrees</code> -- Git Worktree Management","text":"<p>Parallel branch management using git worktrees.</p>"},{"location":"api/#functions_32","title":"Functions","text":""},{"location":"api/#add_worktreebranch-str-path-path-none-none-path","title":"<code>add_worktree(branch: str, path: Path | None = None) -&gt; Path</code>","text":"<p>Create a new git worktree for a branch.</p>"},{"location":"api/#list_worktrees-listdict","title":"<code>list_worktrees() -&gt; list[dict]</code>","text":"<p>List all active worktrees.</p>"},{"location":"api/#remove_worktreebranch-str-bool","title":"<code>remove_worktree(branch: str) -&gt; bool</code>","text":"<p>Remove a worktree.</p>"},{"location":"api/#coretwo_repo-dual-repository-structure","title":"<code>core.two_repo</code> -- Dual-Repository Structure","text":"<p>Manage experiments/ vs clean/ separation.</p>"},{"location":"api/#functions_33","title":"Functions","text":""},{"location":"api/#init_two_repoproject_path-path-bool","title":"<code>init_two_repo(project_path: Path) -&gt; bool</code>","text":"<p>Set up the dual-repo directory structure.</p>"},{"location":"api/#promotesource-str-target-str-clean-bool","title":"<code>promote(source: str, target: str = \"clean\") -&gt; bool</code>","text":"<p>Promote validated code from experiments/ to clean/.</p>"},{"location":"api/#status-dict","title":"<code>status() -&gt; dict</code>","text":"<p>Show what is in each side of the dual-repo.</p>"},{"location":"api/#coreprompt_queue-task-queue","title":"<code>core.prompt_queue</code> -- Task Queue","text":"<p>Queue management for batch task execution.</p>"},{"location":"api/#functions_34","title":"Functions","text":""},{"location":"api/#add_taskdescription-str-str","title":"<code>add_task(description: str) -&gt; str</code>","text":"<p>Add a task to the queue. Returns task ID.</p>"},{"location":"api/#list_tasks-listdict","title":"<code>list_tasks() -&gt; list[dict]</code>","text":"<p>List all queued tasks.</p>"},{"location":"api/#run_queue-listdict","title":"<code>run_queue() -&gt; list[dict]</code>","text":"<p>Execute all queued tasks sequentially.</p>"},{"location":"api/#clear_queue-int","title":"<code>clear_queue() -&gt; int</code>","text":"<p>Clear all tasks from the queue.</p>"},{"location":"api/#coretask_spooler-background-task-execution","title":"<code>core.task_spooler</code> -- Background Task Execution","text":"<p>Background execution of spooled tasks.</p>"},{"location":"api/#functions_35","title":"Functions","text":""},{"location":"api/#spool_taskcommand-str-str","title":"<code>spool_task(command: str) -&gt; str</code>","text":"<p>Add a task to the background spooler.</p>"},{"location":"api/#get_task_statustask_id-str-dict","title":"<code>get_task_status(task_id: str) -&gt; dict</code>","text":"<p>Check the status of a spooled task.</p>"},{"location":"api/#list_spooled-listdict","title":"<code>list_spooled() -&gt; list[dict]</code>","text":"<p>List all spooled tasks with their status.</p>"},{"location":"api/#corelazy_mcp-lazy-mcp-loading","title":"<code>core.lazy_mcp</code> -- Lazy MCP Loading","text":"<p>Deferred loading of MCP servers to reduce startup time.</p>"},{"location":"api/#functions_36","title":"Functions","text":""},{"location":"api/#lazy_loadtier-str-dict","title":"<code>lazy_load(tier: str) -&gt; dict</code>","text":"<p>Load an MCP tier on demand (only when first needed).</p>"},{"location":"api/#is_loadedtier-str-bool","title":"<code>is_loaded(tier: str) -&gt; bool</code>","text":"<p>Check if a tier has been loaded.</p>"},{"location":"api/#coremulti_project-project-workspace","title":"<code>core.multi_project</code> -- Project Workspace","text":"<p>Multi-project management from a single workspace.</p>"},{"location":"api/#functions_37","title":"Functions","text":""},{"location":"api/#register_projectname-str-path-path-dict","title":"<code>register_project(name: str, path: Path) -&gt; dict</code>","text":"<p>Register a project in the global workspace.</p>"},{"location":"api/#list_projects-listdict","title":"<code>list_projects() -&gt; list[dict]</code>","text":"<p>List all registered ricet projects.</p>"},{"location":"api/#switch_projectname-str-path","title":"<code>switch_project(name: str) -&gt; Path</code>","text":"<p>Switch the active project context.</p>"},{"location":"api/#coremarkdown_commands-markdown-command-parsing","title":"<code>core.markdown_commands</code> -- Markdown Command Parsing","text":"<p>Parse and execute code blocks from markdown files.</p>"},{"location":"api/#functions_38","title":"Functions","text":""},{"location":"api/#parse_commandsmd_path-path-listdict","title":"<code>parse_commands(md_path: Path) -&gt; list[dict]</code>","text":"<p>Extract fenced code blocks from a markdown file.</p>"},{"location":"api/#execute_commandscommands-listdict-listdict","title":"<code>execute_commands(commands: list[dict]) -&gt; list[dict]</code>","text":"<p>Execute extracted commands sequentially, reporting pass/fail for each.</p>"},{"location":"architecture/","title":"Architecture","text":"<p>This page describes the system architecture, module relationships, and data flow within ricet.</p>"},{"location":"architecture/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>graph TB\n    User[\"User / Terminal\"]\n    CLI[\"cli/main.py&lt;br/&gt;Typer CLI\"]\n    Dashboard[\"cli/dashboard.py&lt;br/&gt;TUI Dashboard\"]\n\n    subgraph Core[\"Core Modules\"]\n        Agents[\"agents.py&lt;br/&gt;Orchestration\"]\n        Session[\"session.py&lt;br/&gt;Session Mgmt\"]\n        Tokens[\"tokens.py&lt;br/&gt;Budget Tracking\"]\n        Knowledge[\"knowledge.py&lt;br/&gt;Encyclopedia\"]\n        MCPs[\"mcps.py&lt;br/&gt;MCP Discovery\"]\n        Router[\"model_router.py&lt;br/&gt;Model Selection\"]\n        Security[\"security.py&lt;br/&gt;Secret Scanning\"]\n        Paper[\"paper.py&lt;br/&gt;LaTeX Pipeline\"]\n        Repro[\"reproducibility.py&lt;br/&gt;Run Logging\"]\n        Resources[\"resources.py&lt;br/&gt;Monitoring\"]\n        Notify[\"notifications.py&lt;br/&gt;Alerts\"]\n        Env[\"environment.py&lt;br/&gt;System Discovery\"]\n        Onboard[\"onboarding.py&lt;br/&gt;Project Init\"]\n        CrossRepo[\"cross_repo.py&lt;br/&gt;Multi-Repo\"]\n        Auto[\"autonomous.py&lt;br/&gt;Scheduled Tasks\"]\n    end\n\n    Bridge[\"claude_flow.py&lt;br/&gt;Claude-Flow Bridge\"]\n    ClaudeFlow[\"claude-flow v3&lt;br/&gt;(optional)\"]\n    ClaudeCLI[\"Claude Code CLI\"]\n    Templates[\"templates/&lt;br/&gt;Project Scaffolding\"]\n\n    User --&gt; CLI\n    User --&gt; Dashboard\n    CLI --&gt; Agents\n    CLI --&gt; Session\n    CLI --&gt; Onboard\n    CLI --&gt; Paper\n    Agents --&gt; Router\n    Agents --&gt; Tokens\n    Agents --&gt; Bridge\n    Session --&gt; Bridge\n    Knowledge --&gt; Bridge\n    MCPs --&gt; Bridge\n    Security --&gt; Bridge\n    Resources --&gt; Bridge\n    CrossRepo --&gt; Bridge\n    Bridge --&gt; ClaudeFlow\n    Bridge -.-&gt;|fallback| ClaudeCLI\n    Onboard --&gt; Templates\n    Agents --&gt; ClaudeCLI\n    Auto --&gt; Agents\n    Notify --&gt; User</code></pre>"},{"location":"architecture/#module-dependency-map","title":"Module Dependency Map","text":"<p>The following diagram shows which core modules depend on which:</p> <pre><code>graph LR\n    CF[\"claude_flow.py\"]\n\n    agents --&gt; CF\n    session --&gt; CF\n    tokens --&gt; CF\n    knowledge --&gt; CF\n    mcps --&gt; CF\n    security --&gt; CF\n    resources --&gt; CF\n    cross_repo --&gt; CF\n    model_router --&gt; CF\n\n    agents --&gt; tokens\n    agents --&gt; model_router\n\n    paper -.-&gt; knowledge\n    reproducibility -.-&gt; security\n\n    autonomous --&gt; agents\n    onboarding -.-&gt; environment</code></pre> <p>Solid arrows indicate direct imports. Dashed arrows indicate indirect or optional relationships.</p>"},{"location":"architecture/#key-observations","title":"Key Observations","text":"<ol> <li> <p><code>claude_flow.py</code> is the central integration point. Nine modules import from it. Every module follows the same fallback pattern: try the bridge, catch <code>ClaudeFlowUnavailable</code>, fall back to a local implementation.</p> </li> <li> <p><code>agents.py</code> is the primary orchestrator. It uses <code>tokens.py</code> for budget checks and <code>model_router.py</code> for model selection before dispatching tasks.</p> </li> <li> <p>Domain-specific modules are isolated. <code>paper.py</code>, <code>reproducibility.py</code>, <code>voice.py</code>, <code>style_transfer.py</code>, <code>meta_rules.py</code>, and <code>automation_utils.py</code> do not depend on the claude-flow bridge and operate independently.</p> </li> <li> <p><code>onboarding.py</code> is entry-only. It is called during <code>ricet init</code> and does not participate in ongoing session execution.</p> </li> </ol>"},{"location":"architecture/#directory-structure","title":"Directory Structure","text":"<pre><code>research-automation/\n\u251c\u2500\u2500 cli/                          # User-facing CLI\n\u2502   \u251c\u2500\u2500 main.py                   # Typer CLI: init, start, overnight, status, etc.\n\u2502   \u251c\u2500\u2500 dashboard.py              # Rich TUI dashboard\n\u2502   \u2514\u2500\u2500 gallery.py                # Figure gallery viewer\n\u2502\n\u251c\u2500\u2500 core/                         # Business logic (45+ modules)\n\u2502   \u251c\u2500\u2500 agents.py                 # Agent types, routing, DAG execution\n\u2502   \u251c\u2500\u2500 session.py                # Session CRUD, snapshots\n\u2502   \u251c\u2500\u2500 tokens.py                 # Token estimation, budget checks\n\u2502   \u251c\u2500\u2500 knowledge.py              # Encyclopedia CRUD, vector search\n\u2502   \u251c\u2500\u2500 mcps.py                   # MCP tier loading, classification\n\u2502   \u251c\u2500\u2500 model_router.py           # Complexity classification, model selection\n\u2502   \u251c\u2500\u2500 security.py               # Secret scanning, immutable files\n\u2502   \u251c\u2500\u2500 paper.py                  # Figures, citations, LaTeX build\n\u2502   \u251c\u2500\u2500 reproducibility.py        # Run logs, artifact registry, hashing\n\u2502   \u251c\u2500\u2500 resources.py              # CPU/RAM/GPU monitoring, checkpoints\n\u2502   \u251c\u2500\u2500 notifications.py          # Slack, email, desktop alerts\n\u2502   \u251c\u2500\u2500 environment.py            # System discovery, conda management\n\u2502   \u251c\u2500\u2500 onboarding.py             # Interactive init questionnaire\n\u2502   \u251c\u2500\u2500 cross_repo.py             # Multi-repo linking, coordinated commits\n\u2502   \u251c\u2500\u2500 autonomous.py             # Scheduled routines, audit logging\n\u2502   \u251c\u2500\u2500 claude_flow.py            # Bridge to claude-flow v3\n\u2502   \u251c\u2500\u2500 style_transfer.py         # Writing style analysis, plagiarism check\n\u2502   \u251c\u2500\u2500 voice.py                  # Audio transcription\n\u2502   \u251c\u2500\u2500 meta_rules.py             # Rule extraction from conversations\n\u2502   \u251c\u2500\u2500 automation_utils.py       # Data helpers, experiment runners\n\u2502   \u251c\u2500\u2500 auto_debug.py             # Automatic error diagnosis\n\u2502   \u251c\u2500\u2500 auto_commit.py            # Auto-commit &amp; push after operations\n\u2502   \u251c\u2500\u2500 auto_docs.py              # Documentation generation\n\u2502   \u251c\u2500\u2500 auto_test.py              # Test generation\n\u2502   \u251c\u2500\u2500 browser.py                # Browser preview\n\u2502   \u251c\u2500\u2500 doability.py              # Task feasibility assessment\n\u2502   \u251c\u2500\u2500 prompt_suggestions.py     # AI-powered next-step suggestions\n\u2502   \u251c\u2500\u2500 mobile.py                 # Mobile PWA support\n\u2502   \u251c\u2500\u2500 mobile_pwa.py             # Progressive Web App features\n\u2502   \u251c\u2500\u2500 rag_mcp.py                # RAG index for MCP discovery\n\u2502   \u251c\u2500\u2500 lazy_mcp.py               # Lazy MCP loading\n\u2502   \u251c\u2500\u2500 markdown_commands.py      # Markdown command parsing\n\u2502   \u251c\u2500\u2500 devops.py                 # Infrastructure automation\n\u2502   \u251c\u2500\u2500 website.py                # GitHub Pages builder\n\u2502   \u251c\u2500\u2500 two_repo.py               # Dual-repo management\n\u2502   \u251c\u2500\u2500 multi_project.py          # Project workspace\n\u2502   \u251c\u2500\u2500 prompt_queue.py           # Task queue management\n\u2502   \u251c\u2500\u2500 task_spooler.py           # Background task execution\n\u2502   \u251c\u2500\u2500 git_worktrees.py          # Git worktree management\n\u2502   \u2514\u2500\u2500 verification.py           # Result verification\n\u2502\n\u251c\u2500\u2500 templates/                    # Copied into new projects\n\u2502   \u251c\u2500\u2500 config/                   # MCP config, settings template\n\u2502   \u2502   \u2514\u2500\u2500 mcp-nucleus.json      # 70+ MCPs in 8 tiers\n\u2502   \u251c\u2500\u2500 knowledge/                # GOAL.md, ENCYCLOPEDIA.md, CONSTRAINTS.md\n\u2502   \u2514\u2500\u2500 paper/                    # main.tex, references.bib, Makefile\n\u2502\n\u251c\u2500\u2500 defaults/                     # Shared defaults (not copied into projects)\n\u2502   \u251c\u2500\u2500 PHILOSOPHY.md             # Core research principles\n\u2502   \u251c\u2500\u2500 LEGISLATION.md            # Non-negotiable rules\n\u2502   \u251c\u2500\u2500 CODE_STYLE.md             # Code style guide\n\u2502   \u251c\u2500\u2500 PROMPTS.md                # Default prompt collection\n\u2502   \u251c\u2500\u2500 MCP_NUCLEUS.json          # Master MCP catalog\n\u2502   \u2514\u2500\u2500 ONBOARDING.md             # Onboarding question bank\n\u2502\n\u251c\u2500\u2500 docker/                       # Container setup\n\u2502   \u251c\u2500\u2500 Dockerfile                # Ubuntu 24.04 + full toolchain\n\u2502   \u251c\u2500\u2500 docker-compose.yml        # Volume mounts, resource limits\n\u2502   \u2514\u2500\u2500 permissions.md            # Permission level documentation\n\u2502\n\u251c\u2500\u2500 scripts/                      # Shell scripts\n\u2502   \u251c\u2500\u2500 setup.sh                  # Initial setup\n\u2502   \u251c\u2500\u2500 setup_claude_flow.sh      # claude-flow installation\n\u2502   \u251c\u2500\u2500 overnight.sh              # Basic overnight runner\n\u2502   \u251c\u2500\u2500 overnight-enhanced.sh     # Enhanced overnight with recovery\n\u2502   \u2514\u2500\u2500 interactive.sh            # Interactive session launcher\n\u2502\n\u251c\u2500\u2500 tests/                        # Test suite\n\u251c\u2500\u2500 docs/                         # Documentation\n\u2514\u2500\u2500 pyproject.toml                # Package metadata and dependencies\n</code></pre>"},{"location":"architecture/#data-flow-project-initialization","title":"Data Flow: Project Initialization","text":"<pre><code>sequenceDiagram\n    participant U as User\n    participant CLI as cli/main.py\n    participant OB as core/onboarding.py\n    participant T as templates/\n    participant G as Git\n\n    U-&gt;&gt;CLI: ricet init my-project\n    CLI-&gt;&gt;OB: collect_answers()\n    OB-&gt;&gt;U: Interactive questionnaire\n    U-&gt;&gt;OB: Goal, type, constraints\n    OB-&gt;&gt;CLI: OnboardingAnswers\n    CLI-&gt;&gt;T: Copy templates to my-project/\n    CLI-&gt;&gt;OB: write_goal_file()\n    CLI-&gt;&gt;OB: write_settings()\n    CLI-&gt;&gt;OB: setup_workspace()\n    CLI-&gt;&gt;G: git init &amp;&amp; git add -A &amp;&amp; git commit\n    CLI-&gt;&gt;U: Project created</code></pre>"},{"location":"architecture/#data-flow-task-execution","title":"Data Flow: Task Execution","text":"<pre><code>sequenceDiagram\n    participant U as User\n    participant M as Master Agent\n    participant R as Model Router\n    participant T as Token Budget\n    participant S as Sub-Agent\n    participant K as Knowledge\n    participant P as Progress\n\n    U-&gt;&gt;M: \"Implement a data loader\"\n    M-&gt;&gt;R: classify_complexity()\n    R--&gt;&gt;M: MEDIUM -&gt; claude-sonnet\n    M-&gt;&gt;T: check_budget()\n    T--&gt;&gt;M: can_proceed: true\n    M-&gt;&gt;S: Route to Coder agent\n    S-&gt;&gt;S: Execute task\n    S-&gt;&gt;K: append_learning(\"What Works\", ...)\n    S-&gt;&gt;P: Update state/PROGRESS.md\n    S--&gt;&gt;M: TaskResult\n    M-&gt;&gt;T: Update usage\n    M--&gt;&gt;U: Result summary</code></pre>"},{"location":"architecture/#data-flow-overnight-mode","title":"Data Flow: Overnight Mode","text":"<pre><code>sequenceDiagram\n    participant CLI as cli/main.py\n    participant TODO as state/TODO.md\n    participant CC as Claude Code CLI\n    participant H as Hooks\n    participant N as Notifications\n    participant DONE as state/DONE\n\n    CLI-&gt;&gt;TODO: Read task list\n    loop Each iteration\n        CLI-&gt;&gt;CC: Execute next task\n        CC-&gt;&gt;H: pre-task.sh\n        CC-&gt;&gt;CC: Process task\n        CC-&gt;&gt;H: post-task.sh (auto-commit)\n        alt Error\n            CC-&gt;&gt;H: on-error.sh (snapshot + notify)\n            H-&gt;&gt;N: Send error notification\n        end\n        CLI-&gt;&gt;DONE: Check for completion signal\n    end\n    CLI-&gt;&gt;N: Send completion notification</code></pre>"},{"location":"architecture/#claude-flow-integration-pattern","title":"Claude-Flow Integration Pattern","text":"<p>Every module that integrates with claude-flow follows the same pattern:</p> <pre><code>from core.claude_flow import ClaudeFlowUnavailable, _get_bridge\n\ndef some_function(args):\n    # Try claude-flow first\n    try:\n        bridge = _get_bridge()\n        result = bridge.some_method(args)\n        return adapt_result(result)\n    except ClaudeFlowUnavailable:\n        pass\n\n    # Fall back to local implementation\n    return local_implementation(args)\n</code></pre> <p>This ensures the system works identically with or without claude-flow installed. The bridge is a singleton (<code>_get_bridge()</code>) that checks for <code>npx</code> and <code>claude-flow@v3alpha</code> availability on first call.</p>"},{"location":"architecture/#agent-type-mapping","title":"Agent Type Mapping","text":"ricet claude-flow Equivalent MASTER hierarchical-coordinator (queen) RESEARCHER researcher CODER coder REVIEWER code-reviewer FALSIFIER security-auditor WRITER api-docs CLEANER refactorer"},{"location":"architecture/#security-architecture","title":"Security Architecture","text":"<pre><code>graph TB\n    subgraph Permissions\n        Safe[\"SAFE&lt;br/&gt;Read, write workspace,&lt;br/&gt;run Python, git ops\"]\n        Moderate[\"MODERATE&lt;br/&gt;Network requests,&lt;br/&gt;create directories\"]\n        Elevated[\"ELEVATED&lt;br/&gt;Delete files, modify config,&lt;br/&gt;push to remote\"]\n        Dangerous[\"DANGEROUS&lt;br/&gt;Sudo, modify secrets,&lt;br/&gt;spend money\"]\n    end\n\n    subgraph Guards\n        SecretScan[\"Secret Scanning&lt;br/&gt;(regex + claude-flow)\"]\n        Immutable[\"Immutable File&lt;br/&gt;Protection\"]\n        Audit[\"Audit Logging&lt;br/&gt;(state/audit.log)\"]\n        Confirm[\"Confirmation&lt;br/&gt;Gates\"]\n    end\n\n    Safe --&gt; SecretScan\n    Moderate --&gt; Audit\n    Elevated --&gt; Confirm\n    Dangerous --&gt; Confirm\n    Immutable --&gt; Safe</code></pre>"},{"location":"architecture/#mcp-tier-architecture","title":"MCP Tier Architecture","text":"<pre><code>graph TB\n    Task[\"Task Description\"]\n    Classify[\"classify_task()\"]\n\n    T0[\"Tier 0: claude-flow&lt;br/&gt;(if available)\"]\n    T1[\"Tier 1: Essential&lt;br/&gt;paper-search, arxiv, git,&lt;br/&gt;github, filesystem, memory\"]\n    T2[\"Tier 2: Data&lt;br/&gt;postgres, sqlite, duckdb, chroma\"]\n    T3[\"Tier 3: ML/DL&lt;br/&gt;jupyter, huggingface, mlflow\"]\n    T4[\"Tier 4: Math&lt;br/&gt;wolfram, sympy\"]\n    T5[\"Tier 5: Paper&lt;br/&gt;latex, overleaf\"]\n    T6[\"Tier 6: Comms&lt;br/&gt;slack, gmail, sendgrid\"]\n    T7[\"Tier 7: Cloud&lt;br/&gt;aws, docker, terraform\"]\n    T8[\"Tier 8: Startup&lt;br/&gt;vercel, gamma, stripe, notion\"]\n\n    Task --&gt; Classify\n    Classify --&gt; T0\n    Classify --&gt; T1\n    Classify --&gt;|\"database, sql\"| T2\n    Classify --&gt;|\"model, training\"| T3\n    Classify --&gt;|\"math, equation\"| T4\n    Classify --&gt;|\"paper, latex\"| T5\n    Classify --&gt;|\"notify, email\"| T6\n    Classify --&gt;|\"deploy, aws\"| T7\n    Classify --&gt;|\"website, slides\"| T8</code></pre> <p>Tier 1 is always loaded. Other tiers activate when task keywords match their trigger words.</p>"},{"location":"faq/","title":"FAQ","text":"<p>Frequently asked questions about ricet.</p>"},{"location":"faq/#general","title":"General","text":""},{"location":"faq/#what-is-ricet","title":"What is ricet?","text":"<p>ricet is a CLI tool and framework that manages scientific research projects using Claude Code. It provides multi-agent orchestration, persistent knowledge, reproducibility enforcement, a paper pipeline, and overnight autonomous execution -- all from a single <code>ricet</code> command.</p>"},{"location":"faq/#who-is-this-for","title":"Who is this for?","text":"<p>Researchers, data scientists, and engineers who use AI assistants for scientific work and want a structured, reproducible, and automated workflow around them.</p>"},{"location":"faq/#what-models-does-it-use","title":"What models does it use?","text":"<p>ricet is built around Anthropic's Claude models. The model router selects between Claude Haiku (simple tasks), Claude Sonnet (medium tasks), and Claude Opus (complex/critical tasks) based on task complexity and remaining budget.</p>"},{"location":"faq/#is-claude-flow-required","title":"Is claude-flow required?","text":"<p>No. claude-flow is an optional integration that enhances orchestration with swarm execution, HNSW vector memory, and 3-tier model routing. Without it, every feature falls back to a built-in implementation. The system works identically either way.</p>"},{"location":"faq/#what-programming-languages-are-supported","title":"What programming languages are supported?","text":"<p>The tool itself is written in Python 3.11+. The agent system can work with any language your research uses -- Python, R, Julia, MATLAB, etc. -- since Claude Code executes arbitrary commands.</p>"},{"location":"faq/#installation","title":"Installation","text":""},{"location":"faq/#what-are-the-minimum-requirements","title":"What are the minimum requirements?","text":"<ul> <li>Python 3.11 or newer</li> <li>Node.js 20 or newer (for Claude Code CLI)</li> <li>Git</li> <li>An Anthropic API key</li> </ul>"},{"location":"faq/#can-i-use-it-without-docker","title":"Can I use it without Docker?","text":"<p>Yes. Docker is optional. The <code>pip install -e .</code> method works without Docker. Docker provides a pre-configured, isolated environment with all system dependencies (LaTeX, ffmpeg, GPU libraries) but is not required for core functionality.</p>"},{"location":"faq/#how-do-i-update","title":"How do I update?","text":"<pre><code>cd research-automation\ngit pull origin master\npip install -e .\n</code></pre>"},{"location":"faq/#does-it-work-on-windows","title":"Does it work on Windows?","text":"<p>The core Python modules work on Windows. Some shell scripts (<code>scripts/*.sh</code>) and hooks (<code>templates/.claude/hooks/*.sh</code>) are Bash-specific and require WSL or Git Bash. Docker mode works on any platform with Docker Desktop.</p>"},{"location":"faq/#usage","title":"Usage","text":""},{"location":"faq/#how-do-i-create-a-new-project","title":"How do I create a new project?","text":"<pre><code>ricet init my-project\n</code></pre> <p>This runs an interactive wizard that asks for your goal, project type, and constraints, then scaffolds the full project directory.</p>"},{"location":"faq/#what-happens-during-ricet-start","title":"What happens during <code>ricet start</code>?","text":"<ol> <li>A session record is created in <code>state/sessions/</code>.</li> <li>The pre-task hook loads knowledge and logs the start.</li> <li>Claude Code launches with the project's agent prompts.</li> <li>The Master agent follows the Progressive Instruction Protocol: Orient, Explore, Plan, Execute, Validate.</li> </ol>"},{"location":"faq/#is-overnight-mode-safe","title":"Is overnight mode safe?","text":"<p>Overnight mode uses <code>--dangerously-skip-permissions</code> to run without interactive approval. The safety model relies on:</p> <ul> <li>Docker isolation (when used)</li> <li>Four-tier permission levels</li> <li>Immutable file protection</li> <li>Secret scanning</li> <li>Audit logging</li> <li>Confirmation gates for dangerous operations (spending money, sending emails)</li> </ul> <p>Review the permission model in <code>docker/permissions.md</code> and configure it for your risk tolerance.</p>"},{"location":"faq/#how-does-token-budget-tracking-work","title":"How does token budget tracking work?","text":"<p>Each session has a token limit (default: 100,000) and a daily limit (default: 500,000). The system estimates token usage at ~4 characters per token (or uses actual metrics from claude-flow). Warnings fire at 50%, 75%, and 90% usage. When budget drops below 20%, all tasks automatically route to Claude Haiku.</p>"},{"location":"faq/#can-i-use-multiple-projects-at-once","title":"Can I use multiple projects at once?","text":"<p>Yes. Each project is a self-contained directory with its own state, knowledge, and configuration. The shared volume (<code>/shared/knowledge</code>) enables knowledge transfer between projects, and <code>core/cross_repo.py</code> supports coordinated commits across linked repositories.</p>"},{"location":"faq/#agents","title":"Agents","text":""},{"location":"faq/#what-are-the-agent-types","title":"What are the agent types?","text":"Agent Role Master Orchestrator -- routes tasks, never executes directly Researcher Literature search and synthesis Coder Code writing and bug fixes Reviewer Code quality audits Falsifier Adversarial validation (Popperian) Writer Paper and documentation writing Cleaner Refactoring and optimization"},{"location":"faq/#can-i-customize-agent-prompts","title":"Can I customize agent prompts?","text":"<p>Yes. Agent prompts live in <code>.claude/agents/</code> inside your project. Edit them directly. Changes take effect on the next session.</p>"},{"location":"faq/#how-does-task-routing-work","title":"How does task routing work?","text":"<p>The Master agent analyzes your request against keyword sets for each agent type. For example, words like \"search\", \"literature\", \"arxiv\" route to the Researcher. Words like \"implement\", \"function\", \"bug\" route to the Coder. You can also explicitly name an agent in your request.</p>"},{"location":"faq/#what-is-the-falsifier-agent","title":"What is the Falsifier agent?","text":"<p>Inspired by Karl Popper's philosophy of science, the Falsifier's job is to destroy results rather than validate them. It checks for data leakage, statistical validity, code correctness, methodology issues, and reproducibility problems. It produces a structured report with critical issues, warnings, and passed checks.</p>"},{"location":"faq/#knowledge","title":"Knowledge","text":""},{"location":"faq/#what-is-the-encyclopedia","title":"What is the encyclopedia?","text":"<p>The file <code>knowledge/ENCYCLOPEDIA.md</code> is a living document that accumulates project knowledge. It has sections for environment info, tricks, design decisions, successful approaches, and failed approaches. Entries are timestamped and can be added automatically after tasks or manually.</p>"},{"location":"faq/#how-does-vector-search-work","title":"How does vector search work?","text":"<p>When claude-flow is installed, knowledge entries are dual-written to both the markdown file and an HNSW vector index. The <code>ricet memory search \"query\"</code> command performs semantic search over indexed entries. Without claude-flow, search falls back to keyword grep.</p>"},{"location":"faq/#is-knowledge-shared-across-projects","title":"Is knowledge shared across projects?","text":"<p>It can be. The Docker setup mounts a <code>/shared/knowledge</code> volume. The <code>sync_shared_knowledge()</code> function copies relevant entries to the shared location, and new projects can read from it.</p>"},{"location":"faq/#paper-pipeline","title":"Paper Pipeline","text":""},{"location":"faq/#what-latex-template-is-included","title":"What LaTeX template is included?","text":"<p>A standard article template with sections for Abstract, Introduction, Methods, Results, Discussion, and Conclusion. It uses natbib for citations and includes packages for math, graphics, hyperlinks, tables, and microtypography.</p>"},{"location":"faq/#how-do-i-generate-publication-quality-figures","title":"How do I generate publication-quality figures?","text":"<pre><code>from core.paper import apply_rcparams, COLORS\n\napply_rcparams()\n# Now all matplotlib plots use publication defaults:\n# Arial font, 300 DPI, clean spines, colorblind-safe colors\n</code></pre>"},{"location":"faq/#how-do-i-add-citations","title":"How do I add citations?","text":"<pre><code>from core.paper import add_citation\n\nadd_citation(\n    \"Smith2024\",\n    author=\"Smith, J.\",\n    title=\"A Great Paper\",\n    year=\"2024\",\n    journal=\"Nature\",\n)\n</code></pre> <p>This appends a BibTeX entry to <code>paper/references.bib</code>. Use <code>\\cite{Smith2024}</code> in your LaTeX.</p>"},{"location":"faq/#reproducibility","title":"Reproducibility","text":""},{"location":"faq/#what-gets-logged-for-each-run","title":"What gets logged for each run?","text":"<ul> <li>Run ID</li> <li>Full command</li> <li>Start and end timestamps</li> <li>Git hash at time of execution</li> <li>All parameters as a dict</li> <li>All metrics as a dict</li> <li>List of artifact paths</li> <li>Status (running, success, failure)</li> </ul>"},{"location":"faq/#how-does-artifact-verification-work","title":"How does artifact verification work?","text":"<p>When you register an artifact, its SHA-256 checksum is recorded. Later, <code>verify_artifact()</code> recomputes the checksum and compares. If the file has changed, it flags a mismatch.</p>"},{"location":"faq/#security","title":"Security","text":""},{"location":"faq/#what-secrets-are-detected","title":"What secrets are detected?","text":"<p>The scanner looks for: API keys, passwords, tokens, AWS credentials, OpenAI keys (<code>sk-...</code>), GitHub PATs (<code>ghp_...</code>), and PEM/private key headers. Custom patterns can be added via the <code>extra_patterns</code> parameter.</p>"},{"location":"faq/#what-files-are-immutable","title":"What files are immutable?","text":"<p><code>.env</code>, <code>.env.local</code>, <code>secrets/*</code>, <code>*.pem</code>, and <code>*.key</code> are never modified by automation. This list is configurable via <code>DEFAULT_IMMUTABLE</code> in <code>core/security.py</code>.</p>"},{"location":"faq/#is-there-an-audit-log","title":"Is there an audit log?","text":"<p>Yes. All autonomous actions are recorded in <code>state/audit.log</code> with ISO timestamps and descriptions. Review this file to verify what the system did during overnight runs.</p>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#the-system-routes-tasks-to-the-wrong-agent","title":"The system routes tasks to the wrong agent","text":"<p>Agent routing is keyword-based. If tasks are misrouted, either:</p> <ol> <li>Be more explicit in your request (\"As the Coder agent, implement...\").</li> <li>Edit the <code>ROUTING_KEYWORDS</code> dict in <code>core/agents.py</code>.</li> <li>Modify the agent prompts in <code>.claude/agents/</code> to better define boundaries.</li> </ol>"},{"location":"faq/#overnight-mode-stops-unexpectedly","title":"Overnight mode stops unexpectedly","text":"<p>Check <code>state/sessions/current.log</code> for error entries. Common causes:</p> <ul> <li>API rate limits (the system retries but may hit a wall)</li> <li>Disk space exhaustion (check <code>df -h</code>)</li> <li>Token budget exceeded (increase <code>session_limit</code> in <code>core/tokens.py</code>)</li> </ul>"},{"location":"faq/#the-knowledge-encyclopedia-is-not-updating","title":"The knowledge encyclopedia is not updating","text":"<p>Verify that:</p> <ol> <li><code>knowledge/ENCYCLOPEDIA.md</code> exists with the expected section headers.</li> <li>The post-task hook (<code>templates/.claude/hooks/post-task.sh</code>) is executable.</li> <li>Section names match exactly: \"Tricks\", \"Decisions\", \"What Works\", \"What Doesn't Work\".</li> </ol>"},{"location":"faq/#claude-flow-commands-fail","title":"claude-flow commands fail","text":"<p>Run the setup script to verify installation:</p> <pre><code>bash scripts/setup_claude_flow.sh\n</code></pre> <p>If claude-flow is unavailable, the system silently falls back to local implementations. No functionality is lost.</p>"},{"location":"features/","title":"Features","text":"<p>A complete reference for every major feature in ricet, designed by Luca Fusar Bassini.</p>"},{"location":"features/#multi-agent-orchestration","title":"Multi-Agent Orchestration","text":"<p>ricet uses a hierarchical agent system where a Master agent routes tasks to six specialized sub-agents.</p>"},{"location":"features/#agent-types","title":"Agent Types","text":"Agent Role Default Budget Master Orchestrator -- parses requests, routes, merges results -- Researcher Literature search, paper synthesis, citation management 15% Coder Code writing, implementation, bug fixes 35% Reviewer Code quality audits, improvement suggestions 10% Falsifier Adversarial validation, data leakage checks, statistical audits 20% Writer Paper sections, documentation, reports 15% Cleaner Refactoring, optimization, dead code removal 5%"},{"location":"features/#task-routing","title":"Task Routing","text":"<p>Tasks are routed using Claude CLI intelligence (with keyword fallback). The Master agent analyzes your request and dispatches it to the best-fit sub-agent. For example:</p> <ul> <li>\"Search for papers on attention mechanisms\" routes to Researcher</li> <li>\"Implement a data loader for the CSV files\" routes to Coder</li> <li>\"Check if there is data leakage in the pipeline\" routes to Falsifier</li> <li>\"Write the methods section\" routes to Writer</li> </ul>"},{"location":"features/#task-dag-execution","title":"Task DAG Execution","text":"<p>Complex tasks can be decomposed into a directed acyclic graph (DAG) of subtasks. The orchestrator resolves dependencies and runs independent tasks in parallel using <code>ThreadPoolExecutor</code>.</p> <p>When claude-flow is available, swarm execution delegates to the bridge for enhanced coordination.</p>"},{"location":"features/#mcp-auto-discovery","title":"MCP Auto-Discovery","text":"<p>ricet includes a catalog of 70+ Model Context Protocol (MCP) integrations organized into eight tiers. MCPs are loaded automatically based on task keywords.</p>"},{"location":"features/#tiers","title":"Tiers","text":"Tier Category Example MCPs Loaded When 1 Essential paper-search, arxiv, git, github, filesystem, memory, fetch Always 2 Data postgres, sqlite, duckdb, chroma \"database\", \"sql\", \"data\" 3 ML/DL jupyter, huggingface, mlflow, wandb \"model\", \"training\", \"neural\" 4 Math wolfram, sympy \"math\", \"equation\", \"derivative\" 5 Paper latex, overleaf \"paper\", \"latex\", \"manuscript\" 6 Communication slack, gmail, sendgrid \"notify\", \"email\", \"slack\" 7 Cloud aws, docker, terraform \"deploy\", \"aws\", \"cloud\" 8 Startup vercel, gamma, stripe, notion \"website\", \"slides\", \"presentation\""},{"location":"features/#tier-0-claude-flow","title":"Tier 0: claude-flow","text":"<p>When claude-flow is installed, it is injected as a tier-0 MCP providing swarm orchestration, HNSW vector memory, and 3-tier model routing.</p>"},{"location":"features/#overnight-mode","title":"Overnight Mode","text":"<p>Run autonomous research while you sleep:</p> <pre><code>ricet overnight --iterations 20\n</code></pre>"},{"location":"features/#how-it-works","title":"How It Works","text":"<ol> <li>Reads <code>state/TODO.md</code> for the task list.</li> <li>Sends each task to Claude via the CLI in <code>--dangerously-skip-permissions</code> mode.</li> <li>After each iteration, checks for a <code>state/DONE</code> signal file.</li> <li>Auto-commits changes after each completed subtask.</li> <li>Monitors resources and creates checkpoints.</li> <li>Sends notifications on errors or completion (if configured).</li> </ol>"},{"location":"features/#enhanced-overnight-script","title":"Enhanced Overnight Script","text":"<p>The <code>scripts/overnight-enhanced.sh</code> script adds:</p> <ul> <li>Automatic error recovery and retry logic</li> <li>Resource monitoring between iterations</li> <li>State snapshots for rollback</li> <li>Configurable iteration limits and timeouts</li> </ul>"},{"location":"features/#knowledge-accumulation","title":"Knowledge Accumulation","text":"<p>Every project maintains a living encyclopedia at <code>knowledge/ENCYCLOPEDIA.md</code>.</p>"},{"location":"features/#sections","title":"Sections","text":"<ul> <li>Environment -- System info, package versions, hardware.</li> <li>Machines -- Local and remote compute resources.</li> <li>Tricks -- Useful patterns and shortcuts discovered during work.</li> <li>Decisions -- Design choices and their rationale.</li> <li>What Works -- Successful approaches for future reference.</li> <li>What Doesn't Work -- Failed approaches to avoid repeating.</li> </ul>"},{"location":"features/#auto-update","title":"Auto-Update","text":"<p>After every task, the post-task hook and knowledge module can append new entries. Each entry includes a timestamp for traceability.</p>"},{"location":"features/#vector-search","title":"Vector Search","text":"<p>When claude-flow is available, knowledge entries are dual-written to both the markdown file and an HNSW vector index. This enables semantic search over accumulated knowledge using <code>ricet memory search \"query\"</code>.</p>"},{"location":"features/#cross-project-knowledge","title":"Cross-Project Knowledge","text":"<p>The shared volume (<code>/shared/knowledge</code>) enables knowledge transfer across projects. Learnings from one project can inform another.</p>"},{"location":"features/#paper-pipeline","title":"Paper Pipeline","text":"<p>A complete academic paper workflow:</p>"},{"location":"features/#latex-template","title":"LaTeX Template","text":"<p>Every project includes a LaTeX template (<code>paper/main.tex</code>) with:</p> <ul> <li>Standard sections: Abstract, Introduction, Methods, Results, Discussion, Conclusion</li> <li>natbib citation support</li> <li>Pre-configured packages: amsmath, graphicx, hyperref, booktabs, microtype</li> </ul>"},{"location":"features/#figure-generation","title":"Figure Generation","text":"<p>Publication-quality figures with colorblind-safe defaults:</p> <pre><code>from core.paper import apply_rcparams, COLORS\n\napply_rcparams()  # Sets matplotlib to publication quality\n\n# Colorblind-safe palette\nCOLORS = {\n    \"blue\": \"#0077BB\",\n    \"orange\": \"#EE7733\",\n    \"green\": \"#009988\",\n    \"red\": \"#CC3311\",\n    \"purple\": \"#AA3377\",\n    \"grey\": \"#BBBBBB\",\n}\n</code></pre> <p>Figure specifications:</p> <ul> <li>Vector PDF output at 300 DPI</li> <li>Arial/Helvetica font, 8-10pt</li> <li>Single column (3.5in) or double column (7in) widths</li> <li>Spines removed from top and right for clean appearance</li> </ul>"},{"location":"features/#citation-management","title":"Citation Management","text":"<pre><code>from core.paper import add_citation\n\nadd_citation(\n    \"Smith2024\",\n    author=\"Smith, J. and Doe, A.\",\n    title=\"Efficient Transformers for Scientific Discovery\",\n    year=\"2024\",\n    journal=\"Nature Machine Intelligence\",\n    doi=\"10.1038/s42256-024-00001-1\",\n)\n</code></pre>"},{"location":"features/#compilation","title":"Compilation","text":"<pre><code>cd paper &amp;&amp; make all\n# Or: ricet paper build\n</code></pre> <p>Runs <code>pdflatex</code> -&gt; <code>biber</code> -&gt; <code>pdflatex</code> -&gt; <code>pdflatex</code> for a complete build.</p>"},{"location":"features/#style-transfer","title":"Style Transfer","text":"<p>The <code>core/style_transfer.py</code> module can analyze the style of a reference paper and apply similar patterns to your writing, with plagiarism checks to ensure originality.</p>"},{"location":"features/#reproducibility","title":"Reproducibility","text":""},{"location":"features/#run-logging","title":"Run Logging","text":"<p>Every experiment run is recorded:</p> <pre><code>from core.reproducibility import RunLog, log_run\n\nrun = RunLog(\n    run_id=\"exp_001\",\n    command=\"python train.py --lr 0.001\",\n    parameters={\"lr\": 0.001, \"epochs\": 50, \"batch_size\": 32},\n    git_hash=\"abc1234\",\n)\nlog_run(run)\n</code></pre> <p>Each log captures: command, parameters, metrics, git hash, start/end timestamps, and artifact references.</p>"},{"location":"features/#artifact-registry","title":"Artifact Registry","text":"<p>Artifacts (models, datasets, figures) are registered with SHA-256 checksums:</p> <pre><code>from core.reproducibility import register_artifact\n\nregister_artifact(\n    \"trained_model\",\n    path=\"outputs/model.pt\",\n    run_id=\"exp_001\",\n    metadata={\"accuracy\": 0.95},\n)\n</code></pre> <p>Integrity can be verified at any time to detect unintended modifications.</p>"},{"location":"features/#dataset-hashing","title":"Dataset Hashing","text":"<p>Datasets are hashed to ensure consistency across runs. If a dataset changes unexpectedly, the system flags a warning.</p>"},{"location":"features/#security","title":"Security","text":""},{"location":"features/#secret-scanning","title":"Secret Scanning","text":"<p>Regex-based detection of API keys, tokens, and private keys in committed files:</p> <ul> <li>OpenAI keys (<code>sk-...</code>)</li> <li>GitHub PATs (<code>ghp_...</code>)</li> <li>AWS credentials</li> <li>PEM/private key files</li> <li>Generic password/token patterns</li> </ul>"},{"location":"features/#immutable-files","title":"Immutable Files","text":"<p>These paths are never modified by automation:</p> <ul> <li><code>.env</code>, <code>.env.local</code></li> <li><code>secrets/*</code></li> <li><code>*.pem</code>, <code>*.key</code></li> </ul>"},{"location":"features/#permission-levels","title":"Permission Levels","text":"Level Examples Policy Safe Read workspace, run Python, git operations Auto-approve Moderate Network requests, create directories Log and proceed Elevated Delete files, modify config, push to remote Ask in interactive, proceed in overnight Dangerous Sudo, modify secrets, spend money, send emails Always ask"},{"location":"features/#audit-logging","title":"Audit Logging","text":"<p>All autonomous actions are recorded in <code>state/audit.log</code> with timestamps and action descriptions.</p>"},{"location":"features/#model-routing","title":"Model Routing","text":"<p>Automatic model selection based on task complexity:</p> Complexity Model Use Cases Simple claude-haiku Formatting, lookups, classification Medium claude-sonnet Code writing, analysis, general tasks Complex claude-opus Debugging, architecture, research Critical claude-opus Validation, paper writing, production"},{"location":"features/#budget-aware-fallback","title":"Budget-Aware Fallback","text":"<p>When the remaining budget drops below 20%, all tasks route to Haiku regardless of complexity.</p>"},{"location":"features/#thinking-mode-selection","title":"Thinking Mode Selection","text":"Task Type Thinking Mode Budget Impact Simple None Minimal Medium Standard Normal Complex Extended 3% of budget Critical Ultra-think Maximum"},{"location":"features/#session-management","title":"Session Management","text":""},{"location":"features/#creating-sessions","title":"Creating Sessions","text":"<pre><code>ricet start                          # Auto-named by timestamp\nricet start --session-name \"exp-v2\"  # Named session\n</code></pre>"},{"location":"features/#session-data","title":"Session Data","text":"<p>Each session tracks:</p> <ul> <li>Name and timestamps</li> <li>Status (active / completed)</li> <li>Token usage estimate</li> <li>Tasks completed and failed</li> <li>Checkpoint history</li> </ul>"},{"location":"features/#snapshots-and-recovery","title":"Snapshots and Recovery","text":"<p>Sessions can be snapshotted for recovery. If an error occurs, the on-error hook saves the current state directory for debugging.</p>"},{"location":"features/#notifications","title":"Notifications","text":""},{"location":"features/#channels","title":"Channels","text":"<ul> <li>Slack -- Via webhook URL</li> <li>Email -- Via SMTP (Gmail and others)</li> <li>Desktop -- Via <code>notify-send</code> on Linux</li> </ul>"},{"location":"features/#throttling","title":"Throttling","text":"<p>Notifications of the same type are throttled to a configurable interval (default: 5 minutes) to prevent spam during long overnight runs.</p>"},{"location":"features/#configuration","title":"Configuration","text":"<pre><code># Set via state/notification_config.json or during project init\n{\n    \"slack_webhook\": \"https://hooks.slack.com/...\",\n    \"email_to\": \"you@example.com\",\n    \"desktop_enabled\": true,\n    \"throttle_seconds\": 300\n}\n</code></pre>"},{"location":"features/#environment-discovery","title":"Environment Discovery","text":"<p>The <code>core/environment.py</code> module auto-detects:</p> <ul> <li>Operating system and version</li> <li>Python version</li> <li>CPU architecture</li> <li>GPU availability and model</li> <li>RAM capacity</li> <li>Conda and Docker availability</li> </ul> <p>This information is written to the project encyclopedia during initialization and used for resource-aware task planning.</p>"},{"location":"features/#cross-repository-coordination","title":"Cross-Repository Coordination","text":""},{"location":"features/#linking-repos","title":"Linking Repos","text":"<p>Via CLI:</p> <pre><code>ricet link /path/to/data-pipeline --name data\nricet link /path/to/shared-lib\n</code></pre> <p>Or programmatically:</p> <pre><code>from core.cross_repo import link_repository\n\nlink_repository(\"data-pipeline\", \"/path/to/data-pipeline\", permissions=[\"read\", \"write\"])\n</code></pre>"},{"location":"features/#coordinated-commits","title":"Coordinated Commits","text":"<p>Push the same commit message across linked repos:</p> <pre><code>from core.cross_repo import coordinated_commit\n\ncoordinated_commit(\"Sync shared schema v2\", repo_names=[\"data-pipeline\", \"analysis\"])\n</code></pre>"},{"location":"features/#rag-indexing","title":"RAG Indexing","text":"<p>Linked repos are automatically indexed for search:</p> <pre><code>from core.cross_repo import index_linked_repo, search_all_linked, reindex_all\n\n# Index a single repo\nindex_linked_repo(repo)\n\n# Search across all linked repos\nresults = search_all_linked(\"attention mechanism\")\n\n# Re-index everything\nreindex_all()\n</code></pre>"},{"location":"features/#permission-boundaries","title":"Permission Boundaries","text":"<p>Each linked repo has explicit permission grants. Cross-repo actions require matching permissions, preventing unauthorized modifications. Linked repos default to read-only.</p>"},{"location":"features/#auto-commit-push","title":"Auto-Commit &amp; Push","text":"<p>Every state-modifying CLI command automatically commits and pushes changes to git. This ensures your work is always versioned and backed up.</p>"},{"location":"features/#configuration_1","title":"Configuration","text":"<p>Control via environment variables:</p> <pre><code>export RICET_AUTO_COMMIT=true   # Enable/disable (default: true)\nexport AUTO_PUSH=true           # Push after commit (default: true)\n</code></pre>"},{"location":"features/#covered-commands","title":"Covered Commands","text":"<p>Auto-commit runs after: <code>init</code>, <code>start</code>, <code>config</code>, <code>overnight</code>, <code>paper build</code>, <code>verify</code>, <code>debug</code>, <code>projects register</code>, <code>worktree add</code>, <code>worktree remove</code>. Read-only commands (<code>status</code>, <code>agents</code>, <code>memory</code>, <code>metrics</code>) are excluded.</p>"},{"location":"features/#claude-powered-intelligence","title":"Claude-Powered Intelligence","text":"<p>Seven core modules use the Claude CLI for intelligent decisions before falling back to keyword heuristics:</p> Module Function What Claude Decides <code>agents</code> <code>route_task</code> Best agent type for a task <code>model_router</code> <code>classify_task_complexity</code> Simple / medium / complex / critical <code>auto_debug</code> <code>suggest_fix</code> One-sentence fix for an error <code>doability</code> <code>assess_doability</code> Feasibility assessment with scores <code>prompt_suggestions</code> <code>suggest_next_steps</code> Next 3-5 research steps <code>verification</code> <code>_extract_factual_sentences</code> Claims with confidence scores <code>onboarding</code> <code>install_inferred_packages</code> Alternative packages on failure"},{"location":"features/#disabling-claude-calls","title":"Disabling Claude Calls","text":"<p>Set <code>RICET_NO_CLAUDE=true</code> to disable Claude CLI calls (useful for CI or offline work). All functions fall back gracefully to keyword heuristics.</p>"},{"location":"features/#adopt-existing-repositories","title":"Adopt Existing Repositories","text":"<p>Transform any existing GitHub repo into a ricet project with one command:</p> <pre><code># Fork + clone + scaffold (recommended -- keeps original intact)\nricet adopt https://github.com/user/repo\n\n# Clone without forking\nricet adopt https://github.com/user/repo --no-fork\n\n# Scaffold a local directory in place\nricet adopt /path/to/local/repo\n\n# Custom name and target directory\nricet adopt https://github.com/user/repo --name my-project --path ~/research\n</code></pre>"},{"location":"features/#what-adopt-does","title":"What Adopt Does","text":"<ol> <li>Forks the repo via <code>gh repo fork --clone</code> (preserves the original).</li> <li>Overlays the ricet workspace structure: <code>knowledge/</code>, <code>state/</code>, <code>config/</code>, <code>paper/</code>.</li> <li>Pre-fills <code>knowledge/GOAL.md</code> from the repository README.</li> <li>Registers the project in <code>~/.ricet/projects.json</code>.</li> <li>Auto-commits the scaffolding changes.</li> </ol>"},{"location":"features/#when-to-use","title":"When to Use","text":"<ul> <li>Bringing an old research repo under ricet management.</li> <li>Starting a new contribution to an open-source project.</li> <li>Setting up a collaborator's fork with ricet tooling.</li> </ul>"},{"location":"features/#collaborative-research","title":"Collaborative Research","text":"<p>Multiple researchers can work on the same ricet repository without conflicts.</p>"},{"location":"features/#how-it-works_1","title":"How It Works","text":"<ol> <li>Sync on start: <code>ricet start</code> runs <code>git pull --rebase</code> before beginning the session.</li> <li>User attribution: Every encyclopedia entry includes the user's git email.</li> <li>Merge-friendly files: <code>.gitattributes</code> uses <code>merge=union</code> for append-only files (<code>ENCYCLOPEDIA.md</code>, <code>PROGRESS.md</code>), which auto-merges without conflicts.</li> </ol>"},{"location":"features/#setup","title":"Setup","text":"<p>Collaboration works automatically. Just ensure both researchers have push access to the repository and run <code>ricet start</code> at the beginning of each session.</p>"},{"location":"features/#cross-repository-rag","title":"Cross-Repository RAG","text":"<p>Link external repositories so agents can search across all your code while only writing to the current project.</p>"},{"location":"features/#linking-repos_1","title":"Linking Repos","text":"<pre><code># Link a repository for RAG search (read-only by default)\nricet link /path/to/other-repo --name my-lib\n\n# Auto-named from directory name\nricet link /path/to/data-pipeline\n\n# Re-index all linked repos\nricet reindex\n\n# Remove a linked repo\nricet unlink my-lib\n</code></pre>"},{"location":"features/#how-indexing-works","title":"How Indexing Works","text":"<p>Linked repos are walked recursively. Files with extensions <code>.py</code>, <code>.md</code>, <code>.txt</code>, <code>.tex</code>, <code>.rst</code>, <code>.yml</code>, <code>.yaml</code>, <code>.json</code> are indexed. Hidden directories, <code>node_modules</code>, and <code>.git</code> are skipped.</p> <p>When claude-flow is available, files are stored in HNSW vector memory for semantic search. Otherwise, a local JSON index is created under <code>state/linked_indexes/</code>.</p>"},{"location":"features/#searching","title":"Searching","text":"<p>Cross-repo results are automatically included when you search knowledge:</p> <pre><code>ricet memory \"attention mechanism implementation\"\n</code></pre> <p>Results from linked repos are tagged with their source name (e.g. <code>[my-lib] def attention(...)</code>).</p>"},{"location":"features/#permission-boundaries_1","title":"Permission Boundaries","text":"<p>Linked repos default to <code>[\"read\"]</code> permissions. The permission system prevents any write operations to linked repos, ensuring you can search but never accidentally modify external code.</p>"},{"location":"features/#connecting-repos-during-setup","title":"Connecting Repos During Setup","text":"<p>When initializing a new project, you can link repos immediately after:</p> <pre><code>ricet init my-project\ncd my-project\nricet link ~/code/shared-utils --name utils\nricet link ~/code/data-pipeline --name data\nricet start   # linked repos are re-indexed on every start\n</code></pre>"},{"location":"features/#connecting-repos-later","title":"Connecting Repos Later","text":"<p>You can link and unlink repos at any time during active development:</p> <pre><code># In your existing project directory\nricet link /path/to/new-dependency\nricet reindex   # manual re-index (also happens on ricet start)\n</code></pre>"},{"location":"features/#auto-documentation","title":"Auto-Documentation","text":"<p>When you develop new code in a ricet project, documentation can update automatically.</p>"},{"location":"features/#manual-trigger","title":"Manual Trigger","text":"<pre><code>ricet docs           # scan project, update docs/API.md, README.md, docs/MODULES.md\nricet docs --force   # run even if RICET_AUTO_DOCS is not set\n</code></pre>"},{"location":"features/#automatic-mode","title":"Automatic Mode","text":"<p>Set <code>RICET_AUTO_DOCS=true</code> to have documentation update after every state-modifying ricet command (via the auto-commit hook) and after every Claude task (via the post-task shell hook).</p> <p>What gets generated:</p> File Content <code>docs/API.md</code> API reference with function signatures and docstrings <code>docs/MODULES.md</code> Table of all modules with public item counts <code>README.md</code> Missing CLI commands appended to the command table <p>Existing content is never overwritten -- only new modules and commands are appended. The system scans <code>src/</code>, <code>lib/</code>, <code>core/</code>, <code>app/</code> and any top-level directories containing <code>.py</code> files.</p>"},{"location":"features/#how-it-works_2","title":"How It Works","text":"<ol> <li>AST-parses every <code>.py</code> file in source directories.</li> <li>Extracts public functions and classes (skips <code>_private</code> names).</li> <li>Compares against existing <code>docs/API.md</code> and <code>README.md</code>.</li> <li>Appends markdown stubs for anything missing.</li> <li>Regenerates <code>docs/MODULES.md</code> as a full index.</li> </ol>"},{"location":"features/#autonomous-routines","title":"Autonomous Routines","text":"<p>Schedule recurring tasks:</p> <pre><code>from core.autonomous import ScheduledRoutine, add_routine\n\nroutine = ScheduledRoutine(\n    name=\"nightly-validation\",\n    description=\"Re-run all experiments and check reproducibility\",\n    schedule=\"daily\",\n    command=\"ricet overnight --iterations 5\",\n)\nadd_routine(routine)\n</code></pre>"},{"location":"features/#confirmation-gates","title":"Confirmation Gates","text":"<p>Routines that involve spending money or sending external communications require explicit user confirmation, even in autonomous mode.</p>"},{"location":"features/#literature-search-citation","title":"Literature Search &amp; Citation","text":"<p>Discover and cite papers directly from the CLI:</p> <pre><code># Search for papers by topic\nricet cite \"attention mechanisms in transformers\"\n\n# Discover related work across multiple databases\nricet discover \"graph neural networks for drug discovery\"\n</code></pre> <p><code>ricet cite</code> searches Semantic Scholar and arXiv, formats results as BibTeX entries, and appends them to <code>paper/references.bib</code>. <code>ricet discover</code> performs a broader literature scan, returning ranked results with abstracts and citation counts.</p>"},{"location":"features/#style-transfer_1","title":"Style Transfer","text":"<p>Analyze a reference paper's writing style and apply it to your own manuscript:</p> <pre><code>ricet paper adapt-style --reference path/to/reference.pdf\n</code></pre> <p>The style transfer module extracts stylistic patterns (sentence structure, formality, section conventions) from the reference and rewrites your paper sections to match, with plagiarism checks to ensure originality.</p>"},{"location":"features/#automated-test-generation","title":"Automated Test Generation","text":"<p>Automatically generate tests for new or modified source files:</p> <pre><code>ricet test-gen\n</code></pre> <p>Scans the project for source files that lack corresponding test coverage and generates pytest-compatible test stubs. Uses Claude to analyze function signatures, docstrings, and usage patterns for meaningful test cases.</p>"},{"location":"features/#package-management","title":"Package Management","text":"<p>Create, build, and publish Python packages from your research code:</p> <pre><code>ricet package init     # Scaffold pyproject.toml, setup.cfg, package structure\nricet package build    # Build sdist and wheel\nricet package publish  # Publish to PyPI (or TestPyPI with --test)\n</code></pre> <p>Useful for turning experiment code into reusable libraries that other projects can depend on.</p>"},{"location":"features/#daily-maintenance","title":"Daily Maintenance","text":"<p>Run all standard health checks in a single command:</p> <pre><code>ricet maintain\n</code></pre> <p>Executes four daily routines:</p> Routine Description <code>test-gen</code> Auto-generate tests for new/changed source files <code>docs-update</code> Auto-update project documentation from source <code>fidelity-check</code> Check GOAL.md alignment and flag drift <code>verify-pass</code> Run verification on recent outputs <p>Maintenance runs automatically at the end of every <code>ricet overnight</code> session, ensuring the project stays healthy between human check-ins.</p>"},{"location":"features/#goal-fidelity","title":"Goal Fidelity","text":"<p>Check whether the project is still aligned with its stated research goal:</p> <pre><code>ricet fidelity\n</code></pre> <p>Compares the current state of the codebase and outputs against <code>knowledge/GOAL.md</code>. Returns a fidelity score (0-100) and flags specific drift areas with recommendations. Integrated into overnight mode as a pre-flight check.</p>"},{"location":"features/#cross-project-learning","title":"Cross-Project Learning","text":"<p>Share learnings between ricet projects:</p> <pre><code>ricet sync-learnings\n</code></pre> <p>Reads the current project's encyclopedia and publishes key patterns, decisions, and what-works/what-doesn't entries to a shared knowledge volume. Other ricet projects can pull these learnings to bootstrap their own knowledge base.</p>"},{"location":"features/#mcp-server-discovery","title":"MCP Server Discovery","text":"<p>Search a catalog of 1300+ Model Context Protocol servers and install them on demand:</p> <pre><code>ricet mcp-search \"database migration\"\n</code></pre> <p>Results include server name, description, install command, and compatibility info. Select a result to install it directly into your project's MCP configuration.</p>"},{"location":"features/#dual-repository-structure","title":"Dual-Repository Structure","text":"<p>Manage a clean separation between experimental and production code:</p> <pre><code>ricet two-repo init       # Set up experiments/ and clean/ directories\nricet two-repo promote    # Promote validated code from experiments/ to clean/\nricet two-repo status     # Show what's in each side\n</code></pre> <p>The <code>experiments/</code> directory is for rapid iteration; <code>clean/</code> holds reviewed, tested code. Promotion requires passing verification checks.</p>"},{"location":"features/#url-browsing","title":"URL Browsing","text":"<p>Fetch and extract text from any URL for use in literature review:</p> <pre><code>ricet browse https://example.com/paper-landing-page\n</code></pre> <p>Uses headless browser automation when available (Puppeteer MCP), falling back to HTTP fetch. Extracts readable text content and stores it in the project knowledge base.</p>"},{"location":"features/#infrastructure-management","title":"Infrastructure Management","text":"<p>Run infrastructure checks, Docker builds, CI/CD setup, and secrets management:</p> <pre><code>ricet infra check     # Verify Docker, CI, dependencies\nricet infra build     # Build project Docker image\nricet infra secrets   # Manage project secrets\nricet infra ci        # Generate/update CI workflow files\n</code></pre>"},{"location":"features/#runbook-execution","title":"Runbook Execution","text":"<p>Parse and execute code blocks from a markdown runbook:</p> <pre><code>ricet runbook docs/setup-runbook.md\n</code></pre> <p>Extracts fenced code blocks from the markdown file and executes them sequentially, reporting pass/fail for each step. Useful for onboarding, environment setup, and reproducible deployment procedures.</p>"},{"location":"features/#autonomous-overnight-enhancements","title":"Autonomous Overnight Enhancements","text":""},{"location":"features/#docker-sandbox","title":"Docker Sandbox","text":"<p>Run overnight sessions inside a Docker container for full isolation:</p> <pre><code>ricet overnight --iterations 30 --docker\n</code></pre> <p>Automatically builds the <code>ricet:latest</code> image if it does not exist, mounts the project directory and Claude credentials, then runs the overnight loop inside the container.</p>"},{"location":"features/#falsifier-auto-trigger","title":"Falsifier Auto-Trigger","text":"<p>After every overnight iteration, the falsifier agent automatically validates results. It checks for data leakage, statistical validity, confounders, and reproducibility issues. No manual intervention needed.</p>"},{"location":"features/#resource-aware-scheduling","title":"Resource-Aware Scheduling","text":"<p>Overnight mode monitors CPU, RAM, and disk usage between iterations. If resources drop below safe thresholds, the run pauses and checkpoints. High memory triggers an automatic checkpoint commit. Old checkpoints are cleaned up to free disk space.</p>"},{"location":"features/#automated-research-workflow","title":"Automated Research Workflow","text":"<p>Run the full research automation pipeline:</p> <pre><code>ricet auto add-routine --name nightly-check --command \"ricet verify\" --schedule daily\nricet auto list-routines\nricet auto monitor --topic \"large language models\"\n</code></pre>"},{"location":"features/#reproducibility-tracking","title":"Reproducibility Tracking","text":"<pre><code>ricet repro log --command \"python train.py\" --run-id exp-001\nricet repro list\nricet repro show --run-id exp-001\nricet repro hash --path data/dataset.csv\n</code></pre> <p>Every experiment run is logged with parameters, git hash, metrics, and SHA-256 artifact checksums.</p>"},{"location":"features/#voice-prompting","title":"Voice Prompting","text":"<p>Transcribe audio instructions and feed them into the agent pipeline:</p> <pre><code>ricet voice\n</code></pre> <p>The voice module:</p> <ol> <li>Accepts an audio file (WAV, MP3, FLAC).</li> <li>Transcribes it to text using whisper-cpp or a compatible backend.</li> <li>Detects the language automatically.</li> <li>Structures the transcription into an actionable research prompt.</li> <li>Routes the structured prompt to the appropriate agent.</li> </ol> <p>Useful for capturing ideas on the go or dictating experiment plans.</p>"},{"location":"features/#mobile-pwa-access","title":"Mobile &amp; PWA Access","text":"<p>Set up remote access to your research project from a mobile device:</p> <pre><code>ricet mobile\n</code></pre> <p>The mobile module generates a Progressive Web App (PWA) configuration that enables:</p> <ul> <li>Remote dashboard access from any device with a browser.</li> <li>Push notifications for overnight mode events.</li> <li>Mobile-optimized prompt input for on-the-go task submission.</li> </ul>"},{"location":"features/#interactive-dashboard","title":"Interactive Dashboard","text":"<p>A Rich-powered terminal UI for monitoring active sessions:</p> <pre><code>ricet dashboard\n</code></pre>"},{"location":"features/#panels","title":"Panels","text":"<ul> <li>Agents -- Active agent types, current tasks, and budget usage.</li> <li>Resources -- CPU, RAM, GPU, and disk utilization.</li> <li>Memory -- Recent knowledge entries and vector memory stats.</li> <li>Progress -- Task completion log and session history.</li> </ul> <p>The dashboard auto-refreshes and provides a single-pane view of your project's status.</p>"},{"location":"features/#figure-gallery","title":"Figure Gallery","text":"<p>Scan, catalog, and organize experiment figures:</p> <pre><code>ricet gallery\n</code></pre> <p>The gallery module:</p> <ul> <li>Recursively scans the project for image files (PNG, PDF, SVG).</li> <li>Groups figures by run ID and experiment.</li> <li>Displays a navigable terminal-based preview.</li> <li>Helps quickly select figures for paper inclusion.</li> </ul>"},{"location":"features/#git-worktree-management","title":"Git Worktree Management","text":"<p>Manage parallel experiment branches using git worktrees:</p> <pre><code>ricet worktree add feature-branch     # Create a new worktree\nricet worktree list                   # List active worktrees\nricet worktree remove feature-branch  # Remove a worktree\n</code></pre> <p>Worktrees let you run concurrent experiments on different branches without stashing or switching, keeping each experiment isolated.</p>"},{"location":"features/#task-queue-spooler","title":"Task Queue &amp; Spooler","text":"<p>Manage background task execution:</p> <pre><code>ricet queue add \"run experiment with lr=0.01\"    # Add a task to the queue\nricet queue list                                 # List queued tasks\nricet queue run                                  # Execute all queued tasks\nricet queue clear                                # Clear the queue\n</code></pre> <p>The task spooler handles batch execution of queued tasks, integrating with the agent system for routing and with the reproducibility module for logging.</p>"},{"location":"features/#website-builder","title":"Website Builder","text":"<p>Generate and deploy a GitHub Pages documentation site:</p> <pre><code>ricet website init       # Scaffold MkDocs site\nricet website build      # Build static site\nricet website deploy     # Deploy to GitHub Pages\n</code></pre> <p>The website builder creates a Material-themed MkDocs site from your project's documentation, API reference, and README.</p>"},{"location":"features/#doability-assessment","title":"Doability Assessment","text":"<p>Assess the feasibility of a task before starting:</p> <p>The doability module analyzes a task description and returns:</p> <ul> <li>A feasibility score (0-100).</li> <li>Risk factors and potential blockers.</li> <li>Estimated complexity classification.</li> <li>Recommendations for approach.</li> </ul> <p>This is used internally by the agent system to plan work and can be triggered via <code>ricet auto</code> routines.</p>"},{"location":"features/#prompt-suggestions","title":"Prompt Suggestions","text":"<p>AI-powered next-step recommendations:</p> <p>The prompt suggestions module analyzes current project state and suggests the next 3-5 research steps. Used internally during interactive sessions to guide the user when they are unsure what to work on next.</p>"},{"location":"features/#rag-powered-mcp-discovery","title":"RAG-Powered MCP Discovery","text":"<p>A searchable index of 1300+ Model Context Protocol servers:</p> <pre><code>ricet mcp-search \"database migration\"\n</code></pre> <p>The RAG MCP module (<code>core/rag_mcp.py</code>) provides:</p> <ul> <li>Keyword-based search over a comprehensive catalog of MCP servers.</li> <li>Task-based suggestions -- describe what you need and get ranked MCP recommendations.</li> <li>On-demand installation -- install suggested MCPs directly from search results.</li> <li>JSON persistence -- save and load custom indexes for project-specific MCP sets.</li> </ul> <p>The full catalog of 1300+ servers is available at <code>defaults/raggable_mcps.md</code>.</p>"},{"location":"features/#paperboat-integration","title":"PaperBoat Integration","text":"<p>For exhaustive cross-discipline paper discovery, ricet recommends PaperBoat -- an AI-powered service that scans thousands of journals daily and delivers personalized paper matches. Useful as a background SOTA knowledge source that updates daily across all disciplines.</p> <p>Referenced in the paper pipeline section of the README and available as a complement to <code>ricet cite</code> and <code>ricet discover</code> for broader literature coverage.</p>"},{"location":"installation/","title":"Installation","text":"<p>ricet supports three installation methods: pip (recommended), Docker, and from source.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>All installation methods require:</p> <ul> <li>Python 3.11+</li> <li>Node.js 20+ (for Claude Code CLI)</li> <li>Git</li> </ul> <p>Install Claude Code globally before proceeding:</p> <pre><code>npm install -g @anthropic-ai/claude-code\n</code></pre> <p>Authenticate with Claude (recommended -- no API key needed):</p> <pre><code>claude auth login\n</code></pre> <p>Alternatively, for CI/headless environments, set an API key:</p> <pre><code>export ANTHROPIC_API_KEY=\"your-key-here\"\n</code></pre>"},{"location":"installation/#method-1-pip-install-recommended","title":"Method 1: pip Install (Recommended)","text":""},{"location":"installation/#basic-install","title":"Basic install","text":"<pre><code>pip install -e .\n</code></pre> <p>This installs the core CLI with minimal dependencies: <code>typer</code>, <code>rich</code>, <code>pyyaml</code>, and <code>python-dotenv</code>.</p>"},{"location":"installation/#with-ml-extras","title":"With ML extras","text":"<pre><code>pip install -e \".[ml]\"\n</code></pre> <p>Adds <code>numpy</code>, <code>pandas</code>, <code>scipy</code>, <code>scikit-learn</code>, <code>matplotlib</code>, and <code>seaborn</code>.</p>"},{"location":"installation/#full-install","title":"Full install","text":"<pre><code>pip install -e \".[all]\"\n</code></pre> <p>Adds everything in <code>ml</code> plus <code>chromadb</code>, <code>sentence-transformers</code>, <code>torch</code>, and <code>jupyter</code>.</p>"},{"location":"installation/#development-install","title":"Development install","text":"<pre><code>pip install -e \".[dev]\"\n</code></pre> <p>Adds <code>pytest</code>, <code>pytest-cov</code>, <code>black</code>, <code>isort</code>, and <code>mypy</code>.</p>"},{"location":"installation/#verify-installation","title":"Verify installation","text":"<pre><code>ricet --version\n</code></pre> <p>Expected output:</p> <pre><code>ricet 0.3.0\n</code></pre>"},{"location":"installation/#method-2-docker","title":"Method 2: Docker","text":"<p>Docker provides a fully isolated environment with all system dependencies pre-installed, including LaTeX, ffmpeg, and GPU support.</p>"},{"location":"installation/#build-the-image","title":"Build the image","text":"<pre><code>cd docker\ndocker compose build\n</code></pre>"},{"location":"installation/#configure-volumes","title":"Configure volumes","text":"<p>Create a <code>.env</code> file in the <code>docker/</code> directory:</p> <pre><code>PROJECT_PATH=/path/to/your/project\nREFERENCE_PATH=/path/to/reference/papers\nOUTPUTS_PATH=/path/to/outputs\nSECRETS_PATH=/path/to/secrets\nSHARED_PATH=/path/to/shared/knowledge\n# If not using `claude auth login`, set an API key:\nANTHROPIC_API_KEY=your-key-here\nGITHUB_TOKEN=your-token-here\n</code></pre>"},{"location":"installation/#run","title":"Run","text":"<pre><code>docker compose up -d\ndocker compose exec research bash\n</code></pre> <p>Inside the container, the <code>ricet</code> command is available and the workspace is mounted at <code>/workspace</code>.</p>"},{"location":"installation/#what-is-included-in-the-docker-image","title":"What is included in the Docker image","text":"Package Purpose Python 3.11 Runtime Node.js + npm Claude Code CLI texlive-full + biber + latexmk LaTeX compilation ffmpeg + libsndfile1 Audio processing (voice input) numpy, pandas, scipy, scikit-learn Scientific computing torch, torchvision, torchaudio Deep learning matplotlib, seaborn, plotly Visualization chromadb, sentence-transformers Vector search jupyter, notebook Interactive computing typer, rich, tqdm CLI and display"},{"location":"installation/#method-3-from-source","title":"Method 3: From Source","text":""},{"location":"installation/#clone-and-install","title":"Clone and install","text":"<pre><code>git clone https://github.com/lucafusarbassini/research-automation\ncd research-automation\npip install -e \".[dev]\"\n</code></pre>"},{"location":"installation/#run-tests","title":"Run tests","text":"<pre><code>pytest\n</code></pre>"},{"location":"installation/#project-layout","title":"Project layout","text":"<pre><code>research-automation/\n\u251c\u2500\u2500 cli/                 # CLI entry point (ricet command)\n\u251c\u2500\u2500 core/                # Python modules (20+ modules)\n\u251c\u2500\u2500 templates/           # Copied into new projects\n\u2502   \u251c\u2500\u2500 config/          # MCP config, settings\n\u2502   \u251c\u2500\u2500 knowledge/       # Encyclopedia, goals\n\u2502   \u2514\u2500\u2500 paper/           # LaTeX template\n\u251c\u2500\u2500 defaults/            # Default prompts, philosophy, code style\n\u251c\u2500\u2500 docker/              # Dockerfile, docker-compose\n\u251c\u2500\u2500 scripts/             # Setup, overnight, interactive\n\u251c\u2500\u2500 tests/               # Test suite\n\u251c\u2500\u2500 docs/                # Documentation\n\u2514\u2500\u2500 pyproject.toml       # Package configuration\n</code></pre>"},{"location":"installation/#optional-claude-flow-integration","title":"Optional: claude-flow Integration","text":"<p>ricet optionally integrates with claude-flow v3 for enhanced orchestration, HNSW vector memory, and 3-tier model routing. When claude-flow is not installed, every module gracefully falls back to its built-in implementation.</p>"},{"location":"installation/#install-claude-flow","title":"Install claude-flow","text":"<pre><code># Automatic setup\nbash scripts/setup_claude_flow.sh\n\n# Or manual\nnpx claude-flow@v3alpha --version\n</code></pre>"},{"location":"installation/#verify-integration","title":"Verify integration","text":"<pre><code>ricet metrics\n</code></pre> <p>If claude-flow is available, metrics will report actual token counts and cost data. Otherwise, character-based estimates are used.</p>"},{"location":"installation/#environment-variables","title":"Environment Variables","text":"Variable Required Description Claude authentication Yes <code>claude auth login</code> (preferred) or <code>ANTHROPIC_API_KEY</code> for CI/headless <code>GITHUB_TOKEN</code> No GitHub access for PRs, issues, Actions <code>NOTIFICATION_WEBHOOK</code> No Slack/webhook URL for notifications <code>SMTP_USER</code> / <code>SMTP_PASSWORD</code> No Email notification credentials"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/#ricet-command-not-found","title":"<code>ricet</code> command not found","text":"<p>Make sure the package is installed in your active Python environment:</p> <pre><code>pip install -e .\nwhich ricet\n</code></pre>"},{"location":"installation/#claude-code-not-found","title":"Claude Code not found","text":"<pre><code>npm install -g @anthropic-ai/claude-code\nclaude --version\n</code></pre>"},{"location":"installation/#docker-build-fails","title":"Docker build fails","text":"<p>Ensure Docker and Docker Compose v2 are installed:</p> <pre><code>docker --version\ndocker compose version\n</code></pre>"},{"location":"installation/#permission-denied-on-scripts","title":"Permission denied on scripts","text":"<pre><code>chmod +x scripts/*.sh\nchmod +x templates/.claude/hooks/*.sh\n</code></pre>"},{"location":"quickstart/","title":"Quickstart: Your First Project in 5 Minutes","text":"<p>This tutorial walks you through creating a research project, running an interactive session, and launching overnight mode.</p>"},{"location":"quickstart/#step-1-install","title":"Step 1: Install","text":"<pre><code># Install Claude Code\nnpm install -g @anthropic-ai/claude-code\n\n# Clone and install research-automation\ngit clone https://github.com/lucafusarbassini/research-automation\ncd research-automation\npip install -e .\n\n# Authenticate with Claude (no API key needed)\nclaude auth login\n</code></pre>"},{"location":"quickstart/#step-2-create-a-project","title":"Step 2: Create a Project","text":"<pre><code>ricet init my-first-project\n</code></pre> <p>The interactive onboarding wizard will ask you:</p> <ol> <li>Project goal -- A one-liner describing what you want to achieve.</li> <li>Project type -- Choose from <code>ml-research</code>, <code>data-analysis</code>, <code>paper-writing</code>, or <code>general</code>.</li> <li>Timeline and constraints -- Budget, deadlines, compute limits.</li> </ol> <p>The command creates a fully scaffolded project directory:</p> <pre><code>my-first-project/\n\u251c\u2500\u2500 .claude/\n\u2502   \u251c\u2500\u2500 CLAUDE.md           # Agent instructions\n\u2502   \u251c\u2500\u2500 agents/             # 7 specialized agent prompts\n\u2502   \u251c\u2500\u2500 skills/             # Paper writing, figure making, code style\n\u2502   \u2514\u2500\u2500 hooks/              # Pre-task, post-task, on-error hooks\n\u251c\u2500\u2500 knowledge/\n\u2502   \u251c\u2500\u2500 GOAL.md             # Your project goal\n\u2502   \u251c\u2500\u2500 ENCYCLOPEDIA.md     # Auto-growing knowledge base\n\u2502   \u2514\u2500\u2500 CONSTRAINTS.md      # Boundaries and rules\n\u251c\u2500\u2500 paper/\n\u2502   \u251c\u2500\u2500 main.tex            # LaTeX template\n\u2502   \u251c\u2500\u2500 references.bib      # Bibliography\n\u2502   \u2514\u2500\u2500 Makefile            # Build automation\n\u251c\u2500\u2500 config/\n\u2502   \u2514\u2500\u2500 settings.yml        # Project settings\n\u2514\u2500\u2500 state/                  # Session logs, progress tracking\n</code></pre>"},{"location":"quickstart/#step-3-start-an-interactive-session","title":"Step 3: Start an Interactive Session","text":"<pre><code>cd my-first-project\nricet start\n</code></pre> <p>This creates a tracked session and launches Claude Code. The agent system follows the Progressive Instruction Protocol:</p> <ol> <li>Orient -- Reads GOAL.md, CONSTRAINTS.md, and TODO.md to understand context.</li> <li>Explore -- Examines relevant code and data, builds a mental model.</li> <li>Plan -- Breaks the goal into subtasks with difficulty estimates.</li> <li>Execute -- Works through subtasks one at a time, checkpointing after each.</li> <li>Validate -- Runs falsifier checks and documents learnings.</li> </ol> <p>Try giving it a task:</p> <pre><code>Search for recent papers on transformer efficiency and summarize the top 5 findings.\n</code></pre> <p>The Master agent routes this to the Researcher agent, which uses paper-search MCPs to find and synthesize literature.</p>"},{"location":"quickstart/#step-4-check-status","title":"Step 4: Check Status","text":"<p>Open a new terminal:</p> <pre><code>cd my-first-project\nricet status\n</code></pre> <p>This displays the current TODO list and progress log.</p>"},{"location":"quickstart/#step-5-run-overnight-mode","title":"Step 5: Run Overnight Mode","text":"<p>For longer tasks, use overnight mode:</p> <pre><code>ricet overnight --iterations 20\n</code></pre> <p>This runs Claude in an autonomous loop:</p> <ul> <li>Reads the TODO list</li> <li>Executes tasks one by one</li> <li>Auto-commits after each subtask</li> <li>Monitors resources and checkpoints progress</li> <li>Stops when all tasks are done or the iteration limit is reached</li> </ul> <p>Check results in the morning:</p> <pre><code>ricet status\ngit log --oneline -20\n</code></pre>"},{"location":"quickstart/#step-6-build-your-paper","title":"Step 6: Build Your Paper","text":"<p>Once you have results:</p> <pre><code># Compile the LaTeX paper\ncd paper\nmake all\n\n# Or use the CLI\nricet paper build\n</code></pre> <p>The paper pipeline provides:</p> <ul> <li>Publication-quality figure generation with colorblind-safe palettes</li> <li>Automatic citation management via BibTeX</li> <li>One-command PDF compilation</li> </ul>"},{"location":"quickstart/#step-7-view-the-dashboard","title":"Step 7: View the Dashboard","text":"<p>For a richer view of your project:</p> <pre><code>ricet dashboard\n</code></pre> <p>The TUI dashboard shows:</p> <ul> <li>Active agents and their status</li> <li>Token budget usage</li> <li>Resource utilization (CPU, RAM, GPU)</li> <li>Recent progress entries</li> </ul>"},{"location":"quickstart/#what-happens-under-the-hood","title":"What Happens Under the Hood","text":"<p>When you run <code>ricet start</code>, the system:</p> <ol> <li>Creates a session record in <code>state/sessions/</code>.</li> <li>Loads tier-1 MCPs (paper search, git, GitHub, filesystem, memory).</li> <li>Activates agent prompts from <code>.claude/agents/</code>.</li> <li>Starts the pre-task hook to log the session and load knowledge.</li> <li>Routes your request through the Master agent to the appropriate specialist.</li> <li>After each task, the post-task hook auto-commits and updates progress.</li> </ol> <p>Token usage is tracked throughout. At 50%, 75%, and 90% of the session budget, you get warnings. When budget is low, the model router automatically switches to cheaper models.</p>"},{"location":"quickstart/#alternative-adopt-an-existing-repository","title":"Alternative: Adopt an Existing Repository","text":"<p>Already have a repo? Use <code>ricet adopt</code> instead of <code>ricet init</code>:</p> <pre><code># Fork a GitHub repo and scaffold it as a ricet project\nricet adopt https://github.com/user/existing-repo\n\n# Or scaffold a local directory in place\nricet adopt /path/to/my-code\n</code></pre> <p>This overlays the ricet workspace structure without disturbing existing code, pre-fills the goal from README, and registers the project.</p>"},{"location":"quickstart/#step-8-link-related-repositories","title":"Step 8: Link Related Repositories","text":"<p>If you work across multiple repos, link them for cross-repository search:</p> <pre><code># Link repos for RAG-powered search\nricet link ~/code/shared-library --name shared\nricet link ~/code/data-pipeline\n\n# Agents can now search across all linked repos\nricet memory \"data preprocessing pipeline\"\n\n# Re-index after external changes\nricet reindex\n</code></pre> <p>Linked repos are read-only -- agents search them for context but only write to the current project.</p>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Read Features for a complete overview of all capabilities.</li> <li>Read Architecture to understand the module relationships.</li> <li>Read API Reference for detailed module documentation.</li> <li>Check the FAQ for common questions.</li> </ul>"}]}